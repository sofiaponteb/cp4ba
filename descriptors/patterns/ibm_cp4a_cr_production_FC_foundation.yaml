###############################################################################
##
##Licensed Materials - Property of IBM
##
##(C) Copyright IBM Corp. 2021. All Rights Reserved.
##
##US Government Users Restricted Rights - Use, duplication or
##disclosure restricted by GSA ADP Schedule Contract with IBM Corp.
##
###############################################################################
apiVersion: icp4a.ibm.com/v1
kind: ICP4ACluster
metadata:
  name: icp4adeploy
  labels:
    app.kubernetes.io/instance: ibm-dba
    app.kubernetes.io/managed-by: ibm-dba
    app.kubernetes.io/name: ibm-dba
    release: 21.0.3
spec:

  ## MUST exist, used to accept ibm license, valid value only can be "accept"
  ibm_license: ""

  appVersion: 21.0.3
  ##########################################################################
  ## This section contains the shared configuration for all CP4A components #
  ##########################################################################
  shared_configuration:

    ## FileNet Content Manager (FNCM) license and possible values are: user, non-production, and production.
    ## This value could be different from the other licenses in the CR.
    sc_deployment_fncm_license: "<Required>"

    ## Business Automation Workflow (BAW) license and possible values are: user, non-production, and production.
    ## This value could be different from the other licenses in the CR.
    sc_deployment_baw_license: "<Required>"

    ## Use this parameter to specify the license for the CP4A deployment and
    ## the possible values are: non-production and production and if not set, the license will
    ## be defaulted to production.  This value could be different from the other licenses in the CR.
    sc_deployment_license: "<Required>"

    ## All CP4A components must use/share the image_pull_secrets to pull images
    image_pull_secrets:
    - admin.registrykey

    ## All CP4A components must use/share the same docker image repository.  For example, if IBM Entitled Registry is used, then
    ## it should be "cp.icr.io".  Otherwise, it will be a local docker registry.
    sc_image_repository: cp.icr.io

    ## Specify the RunAsUser for the security context of the pod.  This is usually a numeric value that corresponds to a user ID.
    ## For non-OCP (e.g., CNCF platforms such as AWS, GKE, etc), this parameter is optional. It is not supported on OCP and ROKS.
    sc_run_as_user:

    images:
      keytool_job_container:
        repository: cp.icr.io/cp/cp4a/ums/dba-keytool-jobcontainer
        tag: 21.0.3-IF007
      dbcompatibility_init_container:
        repository: cp.icr.io/cp/cp4a/aae/dba-dbcompatibility-initcontainer
        tag: 21.0.3-IF007
      keytool_init_container:
        repository: cp.icr.io/cp/cp4a/ums/dba-keytool-initcontainer
        tag: 21.0.3-IF007
      umsregistration_initjob:
        repository: cp.icr.io/cp/cp4a/aae/dba-umsregistration-initjob
        tag: 21.0.3-IF007

      ## All CP4A components should use this pull_policy as the default, but it can override by each component
      pull_policy: IfNotPresent

    ## Used to sign all CP4A internal certificates for internal services communications. In most cases, this value should not be changed.
    ## All CP4A components must use/share the root_ca_secret in order for integration
    root_ca_secret: icp4a-root-ca

    ## Shared secret containing a wildcard certificate (and concatenated signers) to be used by all routes, unless overwritten for a specific component route.
    ## If this is not defined, all external routes will be signed with root_ca_secret.
    ## From 21.0.3 on, this parameter only apply for non-OCP deployment.  In an OCP deployment, all external traffics are going through Zen's front door and custom TLS certifcates must  be integrated with Zen's front door.  
    ## Please refer to https://www.ibm.com/docs/en/cloud-paks/1.0?topic=cc-updating-custom-hostname-tls-secret-by-using-configmap for more information.
    external_tls_certificate_secret:

    ## CP4A patterns or capabilities to be deployed.  This CR represents the "foundation" pattern, which includes the following
    ## mandatory components: icn (BAN/Navigator), rr (Resource Registry) and optional components: ums, bas, and bai
    sc_deployment_patterns: foundation

    ## The optional components to be installed if listed here.  This is normally populated by the User script based on input from the user.  User can
    ## also manually specify the optional components to be deployed here.  For this foundation CR, the optional components are: ums, bas and bai
    sc_optional_components:

    ## The deployment type as selected by the user.  Possible values are: Starter and Production.
    sc_deployment_type: Production

    ## The deployment context, which has a default value of "CP4A".  Unless you are instructed to change this value or 
    ## know the reason to change this value, please leave the default value.
    sc_deployment_context: "CP4A"

    ## The platform to be deployed specified by the user.  Possible values are: OCP and other.  This is normally populated by the User script
    ## based on input from the user.
    sc_deployment_platform:

    ## This is the deployment hostname suffix, this is optional and the default hostname suffix will be used as {meta.namespace}.router-canonicalhostname
    # sc_deployment_hostname_suffix: "{{ meta.namespace }}"

    ## For ROKS, this is used to enable the creation of ingresses. The default value is "false", which routes will be created.
    sc_ingress_enable: false

    ## For ROKS Ingress, provide TLS secret name for Ingress controller. If you are not using ROKS, comment out this line.
    sc_ingress_tls_secret_name: <Required>

    ## If the root certificate authority (CA) key of the external service is not signed by the operator root CA key, provide the TLS certificate of
    ## the external service to the component's truststore.
    trusted_certificate_list: []

    ## Shared encryption key secret name that is used for Workflow or Workstream Services and Process Federation Server integration.
    ## This secret is also used by Workflow and BAStudio to store AES encryption key.
    encryption_key_secret: ibm-iaws-shared-key-secret

    ## This is the deployment hostname suffix, this is optional and the default hostname suffix will be used as {meta.namespace}.router-canonicalhostname
    # sc_deployment_hostname_suffix: "{{ meta.namespace }}"

    ## On OCP 3.x and 4.x, the User script will populate these three (3) parameters based on your input for "production" deployment.
    ## If you manually deploying without using the User script, then you would provide the different storage classes for the slow, medium
    ## and fast storage parameters below.  If you only have 1 storage class defined, then you can use that 1 storage class for all 3 parameters.
    ## sc_block_storage_classname is for Zen, Zen requires/recommends block storage (RWO) for metastoreDB
    storage_configuration:
      sc_slow_file_storage_classname: "<Required>"
      sc_medium_file_storage_classname: "<Required>"
      sc_fast_file_storage_classname: "<Required>"
      sc_block_storage_classname: "<Required>"

    # Enables or disables the deployment of AutomationBase from IBM Automation foundation.
    # AutomationBase is deployed only if Business Automation Insights is part of the ICP4BA deployment
    # and this parameter is set to true.
    # Set this parameter to false to deploy a custom configuration of AutomationBase or
    # to customize an existing instance with no risk of the ICP4BA operator overriding it
    # with the default configuration.
    # Default: true
    sc_install_automation_base: true

  ## The beginning section of LDAP configuration for CP4A
  ldap_configuration:
    ## The possible values are: "IBM Security Directory Server" or "Microsoft Active Directory"
    lc_selected_ldap_type: "<Required>"

    ## The name of the LDAP server to connect
    lc_ldap_server: "<Required>"

    ## The port of the LDAP server to connect.  Some possible values are: 389, 636, etc.
    lc_ldap_port: "<Required>"

    ## The LDAP bind secret for LDAP authentication.  The secret is expected to have ldapUsername and ldapPassword keys.  Refer to Knowledge Center for more info.
    lc_bind_secret: ldap-bind-secret

    ## The LDAP base DN.  For example, "dc=example,dc=com", "dc=abc,dc=com", etc
    lc_ldap_base_dn: "<Required>"

    ## Enable SSL/TLS for LDAP communication. Refer to Knowledge Center for more info.
    lc_ldap_ssl_enabled: true

    ## The name of the secret that contains the LDAP SSL/TLS certificate.
    lc_ldap_ssl_secret_name: "<Required>"

    ## The LDAP user name attribute. Semicolon-separated list that must include the first RDN user distinguished names. One possible value is "*:uid" for TDS and "user:sAMAccountName" for AD. Refer to Knowledge Center for more info.
    lc_ldap_user_name_attribute: "<Required>"

    ## The LDAP user display name attribute. One possible value is "cn" for TDS and "sAMAccountName" for AD. Refer to Knowledge Center for more info.
    lc_ldap_user_display_name_attr: "<Required>"

    ## The LDAP group base DN.  For example, "dc=example,dc=com", "dc=abc,dc=com", etc
    lc_ldap_group_base_dn: "<Required>"

    ## The LDAP group name attribute.  One possible value is "*:cn" for TDS and "*:cn" for AD. Refer to Knowledge Center for more info.
    lc_ldap_group_name_attribute: "*:cn"

    ## The LDAP group display name attribute.  One possible value for both TDS and AD is "cn". Refer to Knowledge Center for more info.
    lc_ldap_group_display_name_attr: "cn"

    ## The LDAP group membership search filter string.  One possible value is "(|(&(objectclass=groupofnames)(member={0}))(&(objectclass=groupofuniquenames)(uniquemember={0})))" for TDS
    ## and "(&(cn=%v)(objectcategory=group))" for AD.
    lc_ldap_group_membership_search_filter: "<Required>"

    ## The LDAP group membership ID map.  One possible value is "groupofnames:member" for TDS and "memberOf:member" for AD.
    lc_ldap_group_member_id_map: "<Required>"

    ## The LDAP recursive search. Set true or false to enable or disable recursive searches.
    lc_ldap_recursive_search: false

    ## The maximum search results. Specify a higher value if you expect more search results.
    lc_ldap_max_search_results: 4500

    ## The User script will uncomment the section needed based on user's input from User script.  If you are deploying without the User script,
    ## uncomment the necessary section (depending if you are using Active Directory (ad) or Tivoli Directory Service (tds)) accordingly.
    # ad:
    #   lc_ad_gc_host: "<Required>"
    #   lc_ad_gc_port: "<Required>"
    #   lc_user_filter: "(&(sAMAccountName=%v)(objectcategory=user))"
    #   lc_group_filter: "(&(cn=%v)(objectcategory=group))"
    # tds:
    #   lc_user_filter: "(&(cn=%v)(objectclass=person))"
    #   lc_group_filter: "(&(cn=%v)(|(objectclass=groupofnames)(objectclass=groupofuniquenames)(objectclass=groupofurls)))"


    ## This section allows to enhance the ldap configuration for the UMS SCIM capability. If lc_user_filter or lc_group_filter cannot handle a custom LDAP filter for user or group searches this section should be enabled.
    ## optional: enables the liberty ldapEntityType configuration and disables the usage of lc_user_filter, lc_group_filter, lc_ldap_group_member_id_map, lc_ldap_user_name_attribute and lc_ldap_group_name_attribute in the UMS capabilities.
    ## for detailed information about the ldapEntityType, loginProperty and groupProperties  parameters please see the liberty documentation: https://www.ibm.com/docs/en/was-liberty/nd?topic=configuration-ldapregistry
    ## default is false
    lc_use_ldap_entity_type:
    ## optional: only used if lc_use_ldap_entity_type is true
    ## default is uid
    lc_ldap_login_property:
    ## optional: only used if lc_use_ldap_entity_type is true
    ## the defaults depends on the lc_selected_ldap_type
    lc_ldap_entity_type_user:
      object_class:
      search_base:
      searchfilter:
    ## optional: only used if lc_use_ldap_entity_type is true
    ## the defaults depends on the lc_selected_ldap_type
    lc_ldap_entity_type_group:
      object_class:
      search_base:
      searchfilter:
    ## optional: only used if lc_use_ldap_entity_type is true
    ## the defaults depends on the lc_selected_ldap_type
    lc_ldap_group_properties:
      # member_attribute:
        # The name of the member. Required if member_attribute is set
        # name:
        # The name of the object class. Required member_attribute is set
        # object_class:
        ## the scope options are: all, direct, nested
        # scope:
      #membership_attribute:
        # The name of the membership. Required if membership_attribute is set
        # name:
        ## the scope options are: all, direct, nested
        # scope:


  ## The beginning section of database configuration for CP4A
  datasource_configuration:
    ## The dc_ssl_enabled parameter is used to support database connection over SSL for DB2/Oracle/PostgreSQL.
    dc_ssl_enabled: true
    ## The database_precheck parameter is used to enable or disable CPE/Navigator database connection check.
    ## If set to "true", then CPE/Navigator database connection check will be enabled.
    ## if set to "false", then CPE/Navigator database connection check will not be enabled.
   # database_precheck: true
    ## The database configuration for ICN (Navigator) - aka BAN (Business Automation Navigator)
    dc_icn_datasource:
      ## Provide the database type from your infrastructure.  The possible values are "db2" or "db2HADR" or "oracle" or "postgresql".  This should be the same as the
      ## GCD and object store configuration above.
      dc_database_type: "<Required>"
      ## Provide the ICN datasource name.  The default value is "ECMClientDS".
      dc_common_icn_datasource_name: "ECMClientDS"
      database_servername: "<Required>"
      ## Provide the database server port.  For Db2, the default is "50000".  For Oracle, the default is "1521"
      database_port: "<Required>"
      ## Provide the name of the database for ICN (Navigator).  For example: "ICNDB"
      database_name: "<Required>"
      ## The name of the secret that contains the DB2/Oracle/PostgreSQL SSL certificate.
      database_ssl_secret_name: "<Required>"
      ## If the database type is Oracle, provide the Oracle DB connection string.  For example, "jdbc:oracle:thin:@//<oracle_server>:1521/orcl"
      dc_oracle_icn_jdbc_url: "<Required>"
      ######################################################################################
      ## If the database type is "Db2HADR", then complete the rest of the parameters below.
      ## Otherwise, remove or comment out the rest of the parameters below.
      ######################################################################################
      dc_hadr_standby_servername: "<Required>"
      ## Provide the standby database server port.  For Db2, the default is "50000".
      dc_hadr_standby_port: "<Required>"
      ## Provide the validation timeout.  If not preference, keep the default value.
      dc_hadr_validation_timeout: 15
      ## Provide the retry internal.  If not preference, keep the default value.
      dc_hadr_retry_interval_for_client_reroute: 15
      ## Provide the max # of retries.  If not preference, keep the default value.
      dc_hadr_max_retries_for_client_reroute: 3
      ## Connection manager for a data source.
      connection_manager:
        ## Minimum number of physical connections to maintain in the pool.
        min_pool_size: 0
        ## Maximum number of physical connections for a pool.
        max_pool_size: 50
        ## Amount of time a connection can be unused or idle until it can be discarded during pool maintenance, if doing so does not reduce the pool below the minimum size.
        max_idle_time: 1m
        ## Amount of time between runs of the pool maintenance thread.
        reap_time: 2m
        ## Specifies which connections to destroy when a stale connection is detected in a pool.
        purge_policy: EntirePool

    ## The database configuration for UMS (User Management Service)
    dc_ums_datasource:
      ## Provide the datasource configuration for oauth
      ## Possible dc_ums_oauth_type values are "derby" for test only and "db2", "oracle", "sqlserver" and "postgresql" for production.
      ## This configuration should be the same as the other datasource configuration in the dc_ums_datasource section.
      ## db2 with HADR is automatically activated if dc_ums_oauth_alternate_hosts and dc_ums_oauth_alternate_ports are set.
      ## For Oracle RAC, specify the host name of the SCAN listener as the value of the dc_ums_oauth_host parameter
      dc_ums_oauth_type: "<Required>"
      ## Provide the database server name or IP address of the database server.
      dc_ums_oauth_host: "<Required>"
      ## Provide the database server port.  For Db2, the default is "50000".  For Oracle, the default is "1521". For MSSQL, the default is "1433"- For PostgreSQL, the default is "5432".
      dc_ums_oauth_port: "<Required>"
      ## Provide the name of the database for UMS.  For example: "UMSDB"
      dc_ums_oauth_name: "<Required>"
      dc_ums_oauth_schema: OAuthDBSchema
      dc_ums_oauth_ssl: true
      dc_ums_oauth_ssl_secret_name: "<Required>"
      ## For "oracle", "sqlserver" and "postgresql" provide the names of the driver files
      dc_ums_oauth_driverfiles:
      ## For db2 HADR only
      dc_ums_oauth_alternate_hosts:
      dc_ums_oauth_alternate_ports:

      ## Provide the datasource configuration for the teamserver
      ## Possible dc_ums_teamserver_type values are "derby" for test only and "db2", "oracle", "sqlserver" and "postgresql" for production.
      ## This configuration should be the same as the other datasource configuration in the dc_ums_datasource section.
      ## db2 with HADR is automatically activated if dc_ums_teamserver_alternate_hosts and dc_ums_teamserver_alternate_ports are set.
      ## For Oracle RAC, specify the host name of the SCAN listener as the value of the dc_ums_teamserver_host parameter
      dc_ums_teamserver_type: "<Required>"
      dc_ums_teamserver_host: "<Required>"
      ## Provide the database server port.  For Db2, the default is "50000".  For Oracle, the default is "1521". For MS SQL, the default is "1433"- For PostgreSQL, the default is "5432".
      dc_ums_teamserver_port: "<Required>"
      ## Provide the name of the database for UMS teamserver.  For example: "UMSDB"
      dc_ums_teamserver_name: "<Required>"
      dc_ums_teamserver_ssl: true
      dc_ums_teamserver_ssl_secret_name: "<Required>"
      ## For "oracle", "sqlserver" and "postgresql" provide the names of the driver files
      dc_ums_teamserver_driverfiles:
      ## For db2 HADR only
      dc_ums_teamserver_alternate_hosts:
      dc_ums_teamserver_alternate_ports:


  ########################################################################
  ########   IBM Business Automation Navigator configuration      ########
  ########################################################################
  navigator_configuration:

    ## Navigator secret that contains user credentials for LDAP and database
    ban_secret_name: ibm-ban-secret

    ## The architecture of the cluster.  This is the default for Linux and should not be changed.
    arch:
      amd64: "3 - Most preferred"

    ## The number of replicas or pods to be deployed.  The default is 2 replica and for high availability in a production env,
    ## it is recommended to have 2 or more.
    replica_count: 2

    ## This is the image repository and tag that correspond to image registry, which is where the image will be pulled.
    image:

      ## The default repository is the IBM Entitled Registry
      repository: cp.icr.io/cp/cp4a/ban/navigator-sso
      tag: ga-3011-icn-if003

      ## This will override the image pull policy in the shared_configuration.
      pull_policy: IfNotPresent

    ## Logging for workloads.  This is the default setting.
    log:
      format: json

    ## This is the initial default resource requests.  If more resources are needed,
    ## make the changes here to meet your requirement.
    resources:
      requests:
        cpu: 500m
        memory: 512Mi
      limits:
        cpu: 1
        memory: 1536Mi

    ## By default "Autoscaling" is enabled with the following settings with a minimum of 1 replca and a maximum of 3 replicas.  Change
    ## this settings to meet your requirement.
    auto_scaling:
      enabled: false
      max_replicas: 3
      min_replicas: 2
      ## This is the default cpu percentage before autoscaling occurs.
      target_cpu_utilization_percentage: 80

    ## Below are the default ICN Production settings.  Make the necessary changes as you see fit.
    icn_production_setting:
      timezone: Etc/UTC
      jvm_initial_heap_percentage: 40
      jvm_max_heap_percentage: 66
      jvm_customize_options:
      icn_jndids_name: ECMClientDS
      icn_schema: ICNDB
      icn_table_space: ICNDB
      allow_remote_plugins_via_http: false
      ## uncomment copy_files_to_war parameter to copy customized files into Navigator web application.
      ## The <custom-dir>/navigator_war_filesources.xml must be located in config volume mapping, which is /opt/ibm/wlp/usr/servers/defaultServer/configDropins/overrides
      # copy_files_to_war: <custom-dir>/navigator_war_filesources.xml

      ## The WalkMe URL references a WalkMe snippet.  This snippet is a piece of JavaScript code that allows WalkMe to be displayed in the application.
      ## Each WalkMe Editor account has a unique snippet code that can be accessed inside the Editor.
      #  walkme_url: https://cdn.walkme.com/users/4e7c687193414395aa0411837a9eee4b/test/walkme_4e7c687193414395aa0411837a9eee4b_https.js

    ## Default settings for monitoring
    monitor_enabled: false
    ## Default settings for logging
    logging_enabled: false

    ## Persistent Volume Claims for Navigator.  The Operator will create the PVC using the names below by default.
    datavolume:
      existing_pvc_for_icn_cfgstore: "icn-cfgstore"
      existing_pvc_for_icn_logstore: "icn-logstore"
      existing_pvc_for_icn_pluginstore: "icn-pluginstore"
      existing_pvc_for_icnvw_cachestore: "icn-vw-cachestore"
      existing_pvc_for_icnvw_logstore: "icn-vw-logstore"
      existing_pvc_for_icn_aspera: "icn-asperastore"

    ## Default values for both rediness and liveness probes.  Modify these values to meet your requirements.
    probe:
      readiness:

        initial_delay_seconds: 120
        period_seconds: 5
        timeout_seconds: 10
        failure_threshold: 6
      liveness:
        initial_delay_seconds: 600
        period_seconds: 5
        timeout_seconds: 5
        failure_threshold: 6

    ## Only use this parameter if you want to override the image_pull_secrets setting in the shared_configuration above.
    image_pull_secrets:
      name: "admin.registrykey"

  ########################################################################
  ########   IBM User and Group Management Service configuration  ########
  ########################################################################
  ums_configuration:
    existing_claim_name:
    dedicated_pods: true
    service_type: Route
    routes_ingress_annotations:
    # your external UMS host name, only required if there is no sc_deployment_hostname_suffix given
    hostname:
    port: 443
    images:
      ums:
        repository: cp.icr.io/cp/cp4a/ums/ums
        tag: 21.0.3-IF007
    admin_secret_name: ibm-dba-ums-secret
    ## optional: create routes for backwards compatibility
    backwards_compatibility_routes:
    ## optional for secure communication with UMS
    external_tls_secret_name:
    ## optional for secure communication with UMS
    external_tls_ca_secret_name:
    ## optional for secure communication with UMS
    external_tls_teams_secret_name:
    ## optional for secure communication with UMS
    external_tls_scim_secret_name:
    ## optional for secure communication with UMS
    external_tls_sso_secret_name:

    use_custom_jdbc_drivers: false
    use_custom_binaries: false
    custom_secret_name:

    oauth:
      ## optional: full DN of an LDAP group that is authorized to manage OIDC clients, in addition to primary admin from admin secret
      client_manager_group:
      ## optional: full DN of an LDAP group that is authorized to manage app_tokens, in addition to primary admin from admin secret
      token_manager_group:
      ## optional: lifetime of OAuth access_tokens. default is 7200s
      access_token_lifetime:
      ## optional: lifetime of app-tokens. default is 366d
      app_token_lifetime:
      ## optional: lifetime of app-passwords. default is 366d
      app_password_lifetime:
      ## optional: maximum number of app-tokens or app-passwords per client. default is 100
      app_token_or_password_limit:
      ## optional: encoding / encryption when storing client secrets in OAuth database. Default is xor for compatibility. Recommended value is PBKDF2WithHmacSHA512
      client_secret_encoding:

    #### If dedicated_pods is set to false, the UMS capabilities sso, scim and teamserver
    #### run in the same pods and share this configuration
    replica_count: 2
    resources:
      limits:
        cpu: 500m
        memory: 512Mi
      requests:
        cpu: 200m
        memory: 256Mi
    autoscaling:
      enabled: true
      min_replicas: 2
      max_replicas: 5
      target_average_utilization: 98
    custom_xml:
    logs:
      traceSpecification: "*=info"

    #### If dedicated_pods is set to true, the UMS capabilities sso, scim and teamserver
    #### run in dedicated pods and are configured separately

    # Configuration for sso pods
    sso:
      replica_count: 2
      resources:
        limits:
          cpu: 500m
          memory: 512Mi
        requests:
          cpu: 200m
          memory: 256Mi
      autoscaling:
        enabled: true
        minReplicas: 2
        maxReplicas: 5
        targetAverageUtilization: 98
      custom_xml:
      logs:
        traceSpecification: "*=info"

    # configuration for scim pods
    scim:
      replica_count: 2
      resources:
        limits:
          cpu: 500m
          memory: 512Mi
        requests:
          cpu: 200m
          memory: 256Mi
      autoscaling:
        enabled: true
        minReplicas: 2
        maxReplicas: 5
        targetAverageUtilization: 98
      custom_xml:
      logs:
        traceSpecification: "*=info"

    # configuration for teamserver pods
    teamserver:
      replica_count: 2
      resources:
        limits:
          cpu: 500m
          memory: 512Mi
        requests:
          cpu: 200m
          memory: 256Mi
      autoscaling:
        enabled: true
        minReplicas: 2
        maxReplicas: 5
        targetAverageUtilization: 98
      custom_xml:
      logs:
        traceSpecification: "*=info"
      # optional, default false: enable debug output for Teamserver-to-BTS migration
      migration_debug: false
      # optional, default false: drop tables in BTS database before Teamserver-to-BTS migration
      migration_droptables: false
      # optional, default false: execute Teamserver-to-BTS migration regardless of Teamserver uninstall
      migration_test: false


  ##################################################################
  ########   Resource Registry configuration                ########
  ##################################################################
  resource_registry_configuration:
    # If you inputed hostname and port here. They will be used always
    # If you are using pattern mode (the shared_configuration.sc_deployment_patterns contains value)
    # Then you don't need to fill the hostname and port. It will use shared_configuration.sc_deployment_hostname_suffix to generate one
    # But if you haven't input suffix. And no hostname port assigned. A error will be reported in operator log during deploy
    # For non pattern mode you must assign a valid hostname and port here
    hostname: "{{ 'rr-' + shared_configuration.sc_deployment_hostname_suffix }}"
    port: 443
    images:
      pull_policy: IfNotPresent
      resource_registry:
        repository: cp.icr.io/cp/cp4a/aae/dba-etcd
        tag: 21.0.3-IF007
    admin_secret_name: resource-registry-admin-secret
    replica_size: 1
    probe:
      liveness:
        initial_delay_seconds: 60
        period_seconds: 10
        timeout_seconds: 5
        success_threshold: 1
        failure_threshold: 3
      readiness:
        initial_delay_seconds: 10
        period_seconds: 10
        timeout_seconds: 5
        success_threshold: 1
        failure_threshold: 3
    resource:
      limits:
        cpu: "500m"
        memory: "512Mi"
      requests:
        cpu: "100m"
        memory: "256Mi"
    auto_backup:
      enable: true
      minimal_time_interval: 300
      pvc_name: "{{ meta.name }}-dba-rr-pvc"
      log_pvc_name: 'cp4a-shared-log-pvc'
      dynamic_provision:
        enable: true
        size: 3Gi
        size_for_logstore:
        storage_class: "{{ shared_configuration.storage_configuration.sc_fast_file_storage_classname }}"

  #############################################################################
  ## This section contains the BAStudio component configurations              #
  ##  it's the optional component: app_designer, ads_designer, bas,           #
  ##                               workflow-authoring                         #
  #############################################################################
  bastudio_configuration:
    # If you inputed hostname and port here. They will be used always
    # If you are using pattern mode (the shared_configuration.sc_deployment_patterns contains value)
    # Then you don't need to fill the hostname and port. It will use shared_configuration.sc_deployment_hostname_suffix to generate one
    # But if you haven't input suffix. And no hostname port assigned. A error will be reported in operator log during deploy
    # For non pattern mode you must assign a valid hostname and port here
    hostname: "{{ 'bas-' + shared_configuration.sc_deployment_hostname_suffix }}"
    port: 443
    images:
      pull_policy: IfNotPresent
      bastudio:
        repository: cp.icr.io/cp/cp4a/bas/bastudio
        tag: 21.0.3-IF007
    #Adjust this one if you created the secret with name other than the default
    admin_secret_name: "{{ meta.name }}-bas-admin-secret"
    #-----------------------------------------------------------------------
    # bastudio admin Secret template will be
    #-----------------------------------------------------------------------
    # apiVersion: v1
    # stringData:
    #   dbPassword: "<Your database password>"
    #   dbUsername: "<Your database username>"
    # kind: Secret
    # metadata:
    #   name: icp4adeploy-bas-admin-secret
    # type: Opaque
    #----------------------------------------
    # Designate an existing LDAP user for the BAStudio admin user.
    admin_user:  "<Required>"
    replica_size: 1
    database:
      # The database type used. Only DB2, Oracle, PostgreSQL, SQLServer supported
      type: "db2"
      # DB2, PostgreSQL, SQLServer - Provide the database server hostname for BAStudio use
      host: "<Required>"
      # DB2, PostgreSQL, SQLServer - Provide the database name for BAStudio use
      # The database provided should be created by the BAStudio SQL script template.
      name: "<Required>"
      # DB2, PostgreSQL, SQLServer - Provide the database server port for BAStudio use
      port: "<Required>"
      # If you want to enable DB2 database automatic client reroute (ACR) for HADR or PostgreSQL Connection Fail-over, you must configure alternative_host and alternative_port. Otherwise, leave them blank.
      alternative_host:
      alternative_port:
      # Enabled SSL for Database is true by default
      ssl_enabled: true
      # Oracle - If you are using Oracle input the oracle database connection URL here
      oracle_url:
      cm_max_pool_size: '50'
      cm_min_pool_size: '2'
      # Enabled the SSL for database is true by default. Please save the TLS certificate used by database in a secret and put the name here
      certificate_secret_name: <Required>
      # If you are using custom JDBC (for example using Oracle or some special DB2 driver). Please set this one to true
      use_custom_jdbc_drivers: false
      # The PVC name which bind to the PV which have the custom JDBC driver files stored
      custom_jdbc_pvc:
      # The custom JDBC file set
      jdbc_driver_files: 'db2jcc4.jar db2jcc_license_cisuz.jar db2jcc_license_cu.jar'
    autoscaling:
      enabled: false
      minReplicas: 1
      maxReplicas: 3
      targetAverageUtilization: 80
    external_connection_timeout: 60s
    # Custom liberty XML configurations
    custom_xml:
    # The secret name which contain custom liberty configurations
    custom_secret_name:
    # The Business Automation Custom XML configurations
    bastudio_custom_xml:
    # If you don't want to use walkme script. You can set this one to false
    use_walkme: true
    max_cached_objects_during_refactoring: 256
    logs:
      # You can find all possible options for this section on liberty document
      # https://www.ibm.com/support/knowledgecenter/SSEQTP_liberty/com.ibm.websphere.liberty.autogen.base.doc/ae/rwlp_config_logging.html
      consoleFormat: 'json'
      consoleLogLevel: 'INFO'
      consoleSource: 'message,trace,accessLog,ffdc,audit'
      traceFormat: 'ENHANCED'
      traceSpecification: '*=info'
      messageFormat: 'SIMPLE'
      max_files: '2'
      max_file_size: '20'
    tls:
      tlsTrustList: []
    liveness_probe:
      initialDelaySeconds: 300
      periodSeconds: 30
      timeoutSeconds: 5
      failureThreshold: 3
      successThreshold: 1
    readiness_probe:
      initialDelaySeconds: 240
      periodSeconds: 10
      timeoutSeconds: 5
      failureThreshold: 5
      successThreshold: 1
    startup_probe:
      period_seconds: 5
      timeout_seconds: 10
      failure_threshold: 120
      success_threshold: 1
    resources:
      bastudio:
        limits:
          cpu: '2'
          memory: '3072Mi'
        requests:
          cpu: '1100m'
          memory: '1752Mi'
      init_process:
        limits:
          cpu: '500m'
          memory: '512Mi'
        requests:
          cpu: '100m'
          memory: '128Mi'
    csrf_referrer:
      whitelist: ''
    environment_config:
      csrf:
        ## Comma-separated list of user agents. For the REST API requests with the path pattern “/rest/bpm/wle/v1/*” that is sent by the agents in the list, the server will not validate the “XSRF-TOKEN” cookie. The value of this property must be a comma-separated list, e.g “agentkeyworkd1, agentkeyworkd2”.
        user_agent_keyword_white_list_for_old_restapi_csrf_check: "java,wink client,httpclient,curl,jersey,httpurlconnection"
        ## Whether to validate the cookie "XSRF-TOKEN" against incoming REST API requests (POST/PUT/DELETE) with the path pattern "/rest/bpm/wle/v1/*". The value must be "true" or "false".
        check_xsrf_for_old_restapi: "true"
    storage:
      # Main switch for the data persistence of BAStudio
      enabled: "true"
      # PVC name used to store the BAStudio server log
      existing_pvc_for_logstore: "cp4a-shared-log-pvc"
      # Size of the PV to store the BAStudio server log. Used when creating the PVC
      size_for_logstore: "10Gi"
      # PVC name used to store the BAStudio server dump files
      existing_pvc_for_dumpstore: "{{ meta.name }}-bastudio-dump-pvc"
      # Size of the PV to store the BAStudio server dump files. Used when creating the PVC
      size_for_dumpstore: "10Gi"
      # PVC name used to store the BAStudio server index files
      existing_pvc_for_index: "{{ meta.name }}-bastudio-index-pvc"
      # Size of the PV to store the BAStudio server index files. Used when creating the PVC
      size_for_index: "10Gi"
      # storage class name used for the PVC when not availble
      storage_class: "{{ shared_configuration.storage_configuration.sc_fast_file_storage_classname }}"
    jms_server:
      storage:
        ## Whether to enable persistent storage for JMS
        persistent: true
        ## Size for JMS persistent storage
        size: "1Gi"
        ## Whether to enable dynamic provisioning for JMS persistent storage
        use_dynamic_provisioning: true
        ## Access modes for JMS persistent storage
        access_modes:
        - ReadWriteOnce
        ## Storage class name for JMS persistent storage
        storage_class: "{{ shared_configuration.storage_configuration.sc_fast_file_storage_classname }}"
    #-----------------------------------------------------------------------
    #  App Engine Playback Server (playback_server) can be only one instance.
    #  This is different from App Engine
    #  (where application_engine_configuration is a list and you can deploy multiple instances).
    #  You should use different database, admin_secret, hostname for playback server and the application engine servers
    #-----------------------------------------------------------------------
    playback_server:
      images:
        pull_policy: IfNotPresent
        db_job:
          repository: cp.icr.io/cp/cp4a/aae/solution-server-helmjob-db
          tag: 21.0.3-IF007
        solution_server:
          repository: cp.icr.io/cp/cp4a/aae/solution-server
          tag: 21.0.3-IF007
      # If you inputed hostname and port here. They will be used always
      # If you are using pattern mode (the shared_configuration.sc_deployment_patterns contains value)
      # Then you don't need to fill the hostname and port. It will use shared_configuration.sc_deployment_hostname_suffix to generate one
      # But if you haven't input suffix. And no hostname port assigned. A error will be reported in operator log during deploy
      # For non pattern mode you must assign a valid hostname and port here
      hostname: "{{ 'ae-pbk-' + shared_configuration.sc_deployment_hostname_suffix }}"
      port: 443
      # Inside the admin secret. There are two must fields
      admin_secret_name: "playback-server-admin-secret"
      #-----------------------------------------------------------------------
      # The playback server admin Secret template will be
      #-----------------------------------------------------------------------
      # apiVersion: v1
      # stringData:
      #   AE_DATABASE_PWD: "<Your database password>"
      #   AE_DATABASE_USER: "<Your database username>"
      #   REDIS_PASSWORD: "<Your Redis server password>"
      # kind: Secret
      # metadata:
      #   name: playback-server-admin-secret
      # type: Opaque
      #-----------------------------------------------------------------------
      # Designate an existing LDAP user for the Playback Application Engine admin user.
      # This user ID should be in the IBM Business Automation Navigator administrator role, as specified as appLoginUsername in the Navigator secret.
      # This user should also belong to the User Management Service (UMS) Teams admin group or the UMS Teams Administrators team.
      # If not, follow the instructions in "Completing post-deployment tasks for Business Automation Studio and Application Engine" in the IBM Documentation to add it to the Navigator Administrator role and UMS team server admin group.
      admin_user: <Required>
      external_tls_secret:
      external_connection_timeout: 90s
      replica_size: 1
      ## When the database type is Db2 you can set this to false, must be set to true when the database type is Oracle, PostgreSQL or SQLSERVER.
      use_custom_jdbc_drivers: false
      service_type: Route
      autoscaling:
        enabled: false
        max_replicas: 5
        min_replicas: 2
        target_cpu_utilization_percentage: 80
      server_identifier: ""
      database:
        # AE Database host name or IP when the database type is Db2, PostgreSQL, SQLSERVER.
        host: <Required>
        # AE Database name when the database type is Db2, PostgreSQL, SQLSERVER.
        name: <Required>
        # AE database port number when the database type is Db2, PostgreSQL, SQLSERVER.
        port: <Required>
        ## If you setup Db2 HADR or PostgreSQL, SQLSERVER Connection Fail-over and want to use it, you need to configure alternative_host and alternative_port, or else, leave is as blank.
        ## If more than one server name is specified, delimit the server names with commas (,). The number of values that is specified for alternative_host must match the number of values that is specified for alternative_port.
        alternative_host:
        alternative_port:
        ## Only Db2, Oracle, PostgreSQL, SQLSERVER are supported.
        type: db2
        ## Required only when the database type is Oracle, both ssl and non-ssl. The format must be purely Oracle descriptor like (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=<your database host/IP>)(PORT=<your database port>))(CONNECT_DATA=(SERVICE_NAME=<your Oracle service name>))).
        oracle_url_without_wallet_directory:
        enable_ssl: true
        ## Required only when type is Oracle and enable_ssl is true. The format must be purely oracle descriptor. SSO wallet directory must be specified and fixed to (MY_WALLET_DIRECTORY=/shared/resources/oracle/wallet).
        oracle_url_with_wallet_directory:
        ## Required only when enable_ssl is true, when the database type is Db2, Oracle, SQLSERVER or PostgreSQL
        db_cert_secret_name: <Required>
        ## Required only when type is oracle and enable_ssl is true.
        oracle_sso_wallet_secret_name:
        ## Optional. If it is empty, the DBASB is default when the database type is Db2 or PostgreSQL; the AE_DATABASE_USER set in the admin_secret_name is default when the database type is Oracle and SQLSERVER.
        current_schema: DBASB
        initial_pool_size: 1
        max_pool_size: 100
        max_lru_cache_size: 1000
        max_lru_cache_age: 600000
        dbcompatibility_max_retries: 30
        dbcompatibility_retry_interval: 10
        ## The persistent volume claim for custom JDBC Drivers if using the custom JDBC drivers is enabled(use_custom_jdbc_drivers is true).
        custom_jdbc_pvc:
      log_level:
        node: info
        browser: 2
      content_security_policy:
        enable: false
        whitelist:
        frame_ancestor:
      env:
        max_size_lru_cache_rr: 1000
        server_env_type: development
        purge_stale_apps_interval: 86400000
        # Number of preview-only automation application must be more to trigger purge,
        apps_threshold: 100
        # Age of preview-only automation application since publish to be stale in milliseconds
        stale_threshold: 172800000
        # Number of preview-only automation services must be more to trigger purge,
        service_threshold: 100
        # Age of preview-only automation service since publish to be stale in milliseconds
        service_stale_threshold: 172800000
        # Service socket connection timeout in milliseconds
        connection_timeout: 120000
        uv_thread_pool_size: 40
        # Set custom enviroment varaible on app engine pods
        custom_environment_variables:
        # # example entry for setting timezone on pod
        # - key: TZ
        #   value: Europe/Warsaw
      max_age:
        auth_cookie: "900000"
        csrf_cookie: "3600000"
        static_asset: "2592000"
        hsts_header: "2592000"
      probe:
        liveness:
          failure_threshold: 5
          initial_delay_seconds: 60
          period_seconds: 10
          success_threshold: 1
          timeout_seconds: 180
        readiness:
          failure_threshold: 5
          initial_delay_seconds: 10
          period_seconds: 10
          success_threshold: 1
          timeout_seconds: 180
      #-----------------------------------------------------------------------
      # If you want better HA experience.
      # - Set the session.use_external_store to true
      # - Fill in your redis server information
      #-----------------------------------------------------------------------
      redis:
        # Your external redis host/ip
        host:
        # Your external redis port
        port: '6379'
        ttl: 1800
        # If your redis enabled TLS connection set this to true
        # You should add redis server CA certificate in tls_trust_list or trusted_certificate_list
        tls_enabled: false
        # If you are using Redis V6 and above with username fill in this field.
        # Otherwise leave this field as empty
        username:
      resource_ae:
        limits:
          cpu: 500m
          memory: 1Gi
        requests:
          cpu: 300m
          memory: 256Mi
      resource_init:
        limits:
          cpu: 500m
          memory: 256Mi
        requests:
          cpu: 100m
          memory: 128Mi
      session:
        check_period: "3600000"
        duration: "1800000"
        max: "10000"
        resave: "false"
        rolling: "true"
        save_uninitialized: "false"
        #-----------------------------------------------------------------------
        # If you want better HA experience.
        # - Set the session.use_external_store to true
        # - Fill in your redis server information
        #-----------------------------------------------------------------------
        use_external_store: "false"
      tls:
        tls_trust_list: []
      # If you want to make the replicate size more than 1 for this cluster. Then you must enable the shared storage
      share_storage:
        enabled: true
        # If you create the PV manually. Then please provide the PVC name bind here
        pvc_name:
        auto_provision:
          enabled: true
          # Required if you enabled the auto provision
          storage_class:
          size: 20Gi
      log_storage:
        enabled: true
        pvc_name: 'cp4a-shared-log-pvc'
        log_file_size: '20M'
        log_rotate_size: 5
        auto_provision:
          enabled: true
          # By default it will reuse the operator shared log pvc. If you assgined other name
          # And enabled the auto provision. We will provision that with fast storage class by default
          # If you want to adjust that please fill in this value.
          storage_class: ""
          size: '5Gi'

  ##############################################################################
  ########      IBM Business Automation Insights (BAI) configuration    ########
  ##############################################################################
  bai_configuration:
    persistence:
      # Set this parameter to false to disable dynamic provisioning as the persistence mode for BAI components.
      useDynamicProvisioning: true
    # Name of a secret that is already deployed and contains custom values for configuration parameters.
    # Default value: none.
    bai_secret: ""
    image_credentials:
      # Specific docker registry for the BAI images.
      # If not set, shared_configuration.sc_image_repository is used.
      registry: cp.icr.io/cp/cp4a
    # Image pull policy for BAI images.
    # If not set, shared_configuration.images.pull_policy is used.
    image_pull_policy: "IfNotPresent"

    # This section allow to enhance the configuration of Kafka clients.
    # Those parameters are not mandatory.
    kafka:
      # Indicates whether event consumption starts at the "earliest" offset or at the "latest" offset.
      # Setting it to "latest" means that events sent before BAI is running are not processed.
      # If you want to process events sent before BAI is running set this parameter to "earliest".
      auto_offset_reset: latest
      # You can provide the name of a ConfigMap that is already deployed to Kubernetes
      # and contains Kafka Consumer and producer properties. Default: none.
      properties_config_map: ""
      # The number of seconds before the socket communication with the Kafka server times out. Default: 10000
      socket_timeout_ms: 10000

    settings:
      # Set it to true to enable Apache Kafka data egress. Default: false.
      egress: true
      # URL of an external Kibana OSS. Default: none.
      external_kibana_url:
      # Provide configuration of Apache Kafka topics.
      # All topics must be prefixed with icp4ba-bai
      # If not set, topics with default names as below are created.
      ingress_topic: "icp4ba-bai-ingress"
      egress_topic: "icp4ba-bai-egress"
      service_topic: "icp4ba-bai-service"

    # Setup of Elasticsearch for BAI.
    setup:
      image:
        repository: cp.icr.io/cp/cp4a/bai/bai-setup
        tag: 21.0.3-IF007
      # The back-off limit property specifies the number of retries before the setup job is considered failed. Default: 6.
      backoff_limit: 7
      resources:
        requests:
          # The minimum memory required, including JVM heap and file system cache, to start the setup pod.
          memory: "50Mi"
          # The minimum amount of CPU required to start the setup pod.
          cpu: "200m"
        limits:
          # The maximum memory, including JVM heap and file system cache, to allocate to the setup pod.
          memory: "120Mi"

    # The BAI Management service. Provides public and internal REST endpoints to manage BAI event processing.
    management:
      # You can use this parameter to customize the hostname of the management service route.
      # If not set, the value of shared_configuration.sc_deployment_hostname_suffix is used.
      hostname: "management.bai.{{ shared_configuration.sc_deployment_hostname_suffix }}"
      # The number of Management service replicas. For High Availability,
      # use at least 2 replicas.
      replicas: 2
      # Optional: Enables SSL with an existing certificate for the automatic creation of the OpenShift route
      # for the Management service.
      # If not specified, the value of shared_configuration.external_tls_certificate_secret parameter is used.
      # If this later parameter is not present, the operator generates a self-signed certificate.
      external_tls_secret_name: "{{ meta.name }}-bai-management-external-tls-secret"
      # Optional. The Certificate Authority (CA) used to sign the external TLS secret for the automatic creation
      # of the OpenShift route for the Management service.
      # If you do not want to provide a CA to sign the external TLS certificate, leave this parameter empty.
      external_tls_ca_secret_name:

    flink_pv:
      # The capacity of the persistent volume. Default: "20Gi"
      capacity: "20Gi"
      # If not set, shared_configuration.sc_dynamic_storage_classname is used as a default value.
      storage_class_name: "{{ shared_configuration.storage_configuration.sc_medium_file_storage_classname }}"
      # Provide the name of an existing claim if one is available. By default, a new persistent volume claim is created.
      existing_claim_name: ""

    flink:
      # Use this parameter to increase log verbosity when Flink jobs process events from custom sources through the event forwarder.
      # Valid values: info and trace. Default: info
      log_level: trace
      # Set this parameter to true to increase log verbosity when Flink jobs process fixed-format events.
      # Valid values: true and false. Default: false
      verbose_logs: true

      # The total size of the Flink task manager process.
      # Corresponding Flink parameter: taskmanager.memory.process.size
      # Valid units: https://ci.apache.org/projects/flink/flink-docs-release-1.11/api/java/org/apache/flink/configuration/MemorySize.MemoryUnit.html
      # Default: 1728mb
      task_manager_memory: '1728mb'
      # The total size of the Apache Flink job manager process.
      # Corresponding Flink parameter: jobmanager.memory.process.size
      # Valid units: https://ci.apache.org/projects/flink/flink-docs-release-1.11/api/java/org/apache/flink/configuration/MemorySize.MemoryUnit.html
      # Default: 1728mb
      job_manager_memory: '1728mb'
      # The number of CPUs that are used by Flink task managers (in CPU units).
      # Corresponding Flink parameter: kubernetes.taskmanager.cpu
      # Default: 1
      task_manager_cpu: 1

      # The number of create, delete and update actions to be performed on document indexes in a single request.
      # Default: 1
      elasticsearch_max_actions: 1
      # The time interval at which to flush the buffered actions, regardless of the number or size of buffered actions.
      # If set to -1, a flush internal of 2000 ms is applied when elasticsearch_max_actions is larger than 1, and
      # the buffer is flushed immediately when elasticsearch_max_actions is 1.
      # Otherwise, the specified interval is used.
      # Default: -1
      elasticsearch_flush_interval_ms: -1

      # The interval between checkpoints of an Apache Flink jobs (in milliseconds). Default: 5000
      job_checkpointing_interval: 5000
      # The name of a ConfigMap object that is already deployed to Kubernetes and contains RocksDB properties for Flink.
      # Optional. Default: none.
      rocks_db_properties_config_map: ""

      # Allows to enable the automatic deployment of an OpenShift route to the Flink web interface.
      # On ROKS, if you set the sc_ingress_enable parameter to true, an Ingress is deployed for the Flink web user interface.
      # Default: false
      create_route: true
      # Optional: Enables SSL with an existing certificate for the automatic creation of the OpenShift route
      # for the Flink UI.
      # If not specified, the value of shared_configuration.external_tls_certificate_secret parameter is used.
      # If this later parameter is not present, the operator generates a self-signed certificate.
      external_tls_secret_name: "{{ meta.name }}-bai-flink-ui-external-tls-secret"
      # Optional. The Certificate Authority (CA) used to sign the external TLS secret for the automatic creation
      # of the OpenShift route for the Flink UI.
      # If you do not want to provide a CA to sign the external TLS certificate, leave this parameter empty.
      external_tls_ca_secret_name:

      # The parameters below configure the memory and CPU requests and limits at Kubernetes level.
      # For the valid units of memory requests and limits,
      # see https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#meaning-of-memory.
      # For the valid units of CPU requests and limits,
      # see https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#meaning-of-cpu.
      # The default values are those included below.
      #
      # The memory request for pods of Apache Flink task managers.
      task_manager_memory_request: '1728Mi'
      # The memory limit for pods of Flink task managers.
      task_manager_memory_limit: '1728Mi'
      # The CPU request for pods of Apache Flink task managers.
      task_manager_cpu_request: 1
      # The CPU limit for pods of Apache Flink task managers.
      task_manager_cpu_limit: 1
      # The memory request for pods of Apache Flink job managers.
      job_manager_memory_request: '1728Mi'
      # The memory limit for pods of Apache Flink job managers.
      job_manager_memory_limit: '1728Mi'
      # The CPU request for pods of Apache Flink job managers.
      job_manager_cpu_request: 1
      # The CPU limit for pods of Apache Flink job managers.
      job_manager_cpu_limit: 1

    # The Flink job for processing BPMN events.
    # Enabled automatically if BAI is selected as an optional component of
    # workflow or workflow-workstreams patterns.
    bpmn:
      # Set to true to enable the Flink job for BAW.
      install: false
      image:
        repository: cp.icr.io/cp/cp4a/bai/bai-bpmn
        tag: 21.0.3-IF007
      # The path to the savepoint or checkpoint from which a job will recover.
      # You can use this path to restart the job from a previous state in case of failure.
      # To use the default workflow of the job, leave this option empty.
      recovery_path: ""
      # The number of parallel instances (task slots) to use for running the processing job.
      # For High Availability, use at least 2 parallel instances.
      parallelism: 2
      # The delay in milliseconds before clearing the Flink states used for summary transformation.
      # This value cannot be set to 0 nor be greater than 30 minutes.
      # Otherwise, the default value applies instead.
      end_aggregation_delay: 10000
      # Set this parameter to true if you want time series
      # to be written to Elasticsearch indexes.
      force_elasticsearch_timeseries: false

    # The Flink job for processing BAW Advanced events.
    # Disabled by default. Can be enabled by setting bawadv.install to true.
    bawadv:
      # Set to true to enable the Flink job for BAWAdv.
      install: false
      image:
        repository: cp.icr.io/cp/cp4a/bai/bai-bawadv
        tag: 21.0.3-IF007
      # The path to the savepoint or checkpoint from which a job will recover.
      # You can use this path to restart the job from a previous state in case of failure.
      # To use the default workflow of the job, leave this option empty.
      recovery_path: ""
      # The number of parallel instances (task slots) to use for running the processing job.
      # For High Availability, use at least 2 parallel instances.
      parallelism: 2

    # The Flink job for processing ICM events.
    # Enabled automatically if BAI is selected as an optional component of
    # workflow or workflow-workstreams patterns.
    icm:
      # Set to true to enable the Flink job for ICM.
      install: false
      image:
        repository: cp.icr.io/cp/cp4a/bai/bai-icm
        tag: 21.0.3-IF007
      # The path to the savepoint or checkpoint from which a job will recover.
      # You can use this path to restart the job from a previous state in case of failure.
      # To use the default workflow of the job, leave this option empty.
      recovery_path: ""
      # The number of parallel instances (task slots) to use for running the processing job.
      # For High Availability, use at least 2 parallel instances.
      parallelism: 2
      # Whether the Flink job for ICM events processes events after completion. Default: false
      process_events_after_completion: false

    # The Flink job for processing ODM events.
    # Enabled automatically if BAI is selected as an optional component of
    # decisions pattern.
    odm:
      # Set to true to enable the Flink job for ODM.
      # For ODM, the bai-flink image is used.
      install: false
      image:
        repository: cp.icr.io/cp/cp4a/bai/bai-flink
        tag: 21.0.3-IF007
      # The path to the savepoint or checkpoint from which a job will recover.
      # You can use this path to restart the job from a previous state in case of failure.
      # To use the default workflow of the job, leave this option empty.
      recovery_path: ""
      # The number of parallel instances (task slots) to use for running the processing job.
      # For High Availability, use at least 2 parallel instances.
      parallelism: 2

    # The Flink job for processing Content events.
    # Enabled automatically if BAI is selected as an optional component of
    # content pattern.
    content:
      # Set to true to enable the Flink job for Content.
      install: false
      image:
        repository: cp.icr.io/cp/cp4a/bai/bai-content
        tag: 21.0.3-IF007
      # The path to the savepoint or checkpoint from which a job will recover.
      # You can use this path to restart the job from a previous state in case of failure.
      # To use the default workflow of the job, leave this option empty.
      recovery_path: ""
      # The number of parallel instances (task slots) to use for running the processing job.
      # For High Availability, use at least 2 parallel instances.
      parallelism: 2

    # The Flink job for processing events from custom sources and events based on Avro schema.
    # Its configuration is automatic for events emitted by ADS and BA ML Workforce Insights.
    # For custom events, its configuration must be filled in the Custom Resource as documented in
    # the Knowledge Center.
    event_forwarder:
      image:
        repository: cp.icr.io/cp/cp4a/bai/bai-event-forwarder
        tag: 21.0.3-IF007
      recovery_path: ""
      # The number of parallel instances (task managers) to use for running the processing job.
      # For High Availability, use at least 2 parallel instances.
      parallelism: 2
      # The list of routing configurations of custom events.
      # The value of this parameter must contain at least one configuration,
      # which is composed of a mandatory Kafka topic name along with
      # an Elasticsearch index or an HDFS bucket, or both.
      configurations:
          # The name of a Kafka topic (source). Must be prefixed by icp4ba-bai
        - kafka_topic: ""
          # The name of an Elasticsearch index (target). Must be prefixed by icp4ba-bai
          elasticsearch_index: ""

    # Configuration of initialization containers.
    init_image:
      image:
        repository: cp.icr.io/cp/cp4a/bai/bai-init
        tag: 21.0.3-IF007

    # Business data dashboarding.
    business_performance_center:
      # Set to false to disable Business Performance Center. Default: true.
      install: true
      ## For SaaS 
      # The name of a secret that is already deployed to Kubernetes,
      # which contains configuration information for the Business Performance Center.
      # If you leave this field empty and an UMS instance is installed by the Cloud Pak,
      # the configuration information is automatically generated and stored in a default secret.
      config_secret_name: ""
      # The port to which the Business Performance Center service API is exposed.
      external_port: 9443
      # The number of Business Performance Center replicas. For High Availability,
      # use at least 2 replicas.
      replicas: 2
      ## For SaaS 
      init_ums:
        image:
          repository: cp.icr.io/cp/cp4a/aae/dba-umsregistration-initjob
          tag: 21.0.3-IF007
      ## For SaaS 
      oidc:
        # The internal communication with single-sign-on (SSO) service.
        # If UMS installation can be reach internally, set this parameter to the UMS SSO service name
        # Otherwise, set it to the SSO external route hostname.
        # If you leave this field empty it will use the default value of the UMS instance installed by the Cloud Pak.
        host: ""
        # The external communication with the UMS single-sign-on (SSO) service.
        # Set this parameter to the SSO external route hostname.
        # If you leave this field empty it will use the default value of the UMS instance installed by the Cloud Pak.
        external_host: ""
        # The host used to retrieve the UMS issuer. Set this parameter to the UMS default route.
        # If you leave this field empty it will use the default value of the UMS instance installed by the Cloud Pak.
        issuer_host: ""
        port: 443
      ## For SaaS 
      # Represents the external communication to the UMS team server service. Set this parameter to the team server external route hostname.
      # If you leave this field empty it will use the default value of the UMS instance installed by the Cloud Pak.
      teamserver_host: ""
      ## For SaaS 
      # The external communication to the UMS SCIM service. Set this parameter to the SCIM external route hostname.
      # If you leave this field empty it will use the default value of the UMS instance installed by the Cloud Pak.
      scim_host: ""
      ## For SaaS 
      # The UUID identifier, which is taken from UMS, of the team that you nominate to be the administration team
      # for Business Performance Center.
      # If no admin_team has been specified, a team named bpc_admins will be created automatically and used by BPC.
      # Default: None
      admin_team: ""
      ## For SaaS 
      # The name of a LDAP group to be used by the BPC admin team. The group should be created beforehand. Default: None
      admin_group: ""
      ## For SaaS 
      # Enable automatic creation of the bpc_admins team in UMS if no UUID has been provided under admin_team parameter. Default: true
      register_admin_team: true
      # Set to true if you want to grant all users access to all data.
      all_users_access: false
      # You can use the redirectURIs parameter to specify the route to access Business Performance Center.
      # The URL must end with a forward slash (/).
      # It is not necessary to specify this parameter when relying on the route created by default.
      redirect_uris: ""
      # The URL to which users are redirected when they log out of Business Performance Center.
      # This URL can be the same as the redirectURIs URL.
      # In this case, users still see the same Business Performance Center window but needs to log in
      # again before they can resume working with Business Performance Center.
      logout_redirect_uris: ""
      # You can use this parameter to customize the hostname of the Business Performance Center route.
      # If not set, the value of shared_configuration.sc_deployment_hostname_suffix is used.
      hostname: "business-performance-center.bai.{{ shared_configuration.sc_deployment_hostname_suffix }}"
      resources:
        limits:
          # The maximum memory, including JVM heap size and file system cache, to allocate to the Business Performance Center pod.
          # Adjust this parameter value for better resource allocation and better performance.
          memory: "2Gi"
          # The maximum amount of CPU to allocate to the Business Performance Center pod.
          # Adjust this parameter value for better resource allocation and better performance.
          cpu: "2000m"
      # Set this parameter to false if you do not want
      # the Business Performance Center plug-in to be automatically installed into Navigator.
      auto_plugin: true
      # Optional: Enables SSL with an existing certificate for the automatic creation of the OpenShift route
      # for the Business Performance Center.
      # If not specified, the value of shared_configuration.external_tls_certificate_secret parameter is used.
      # If this later parameter is not present, the operator generates a self-signed certificate.
      external_tls_secret_name: "{{ meta.name }}-bai-bperf-external-tls-secret"
      # Optional. The Certificate Authority (CA) used to sign the external TLS secret for the automatic creation
      # of the OpenShift route for the Business Performance Center.
      # If you do not want to provide a CA to sign the external TLS certificate, leave this parameter empty.
      external_tls_ca_secret_name:


  #############################################################################
  ######## IBM Business Automation Application server  configurations  ########
  ##  This section contains the configurations for                           ##
  ##  * App Engine Server                                                    ##
  ##  it's the optional component and will be installed when                 ##
  ##  patterns include: application, workflow, workstreams,                  ##
  ##                    workflow-workstreams or document_processing          ##
  #############################################################################
  application_engine_configuration:
  ## The application_engine_configuration is a list, you can deploy multiple instances of AppEngine, you can assign different configurations for each instance.
  ## For each instance, application_engine_configuration.name, database, admin_secret_name and hostname must be assigned to different values.
  ## Each application_engine_configuration.name can consist of lowercase alphanumeric characters or '-', and must start and end with an alphanumeric character. Keep the instance name as short as possible.
  ## You should use different database, admin_secret_name, hostname for playback server and the application engine servers
  - name: workspace
    images:
      pull_policy: IfNotPresent
      solution_server:
        repository: cp.icr.io/cp/cp4a/aae/solution-server
        tag: 21.0.3-IF007
      db_job:
        repository: cp.icr.io/cp/cp4a/aae/solution-server-helmjob-db
        tag: 21.0.3-IF007
    # If you inputed hostname and port here. They will be used always
    # If you are using pattern mode (the shared_configuration.sc_deployment_patterns contains value)
    # Then you don't need to fill the hostname and port. It will use shared_configuration.sc_deployment_hostname_suffix to generate one
    # But if you haven't input suffix. And no hostname port assigned. A error will be reported in operator log during deploy
    # For non pattern mode you must assign a valid hostname and port here
    hostname: "{{ 'ae-workspace-' + shared_configuration.sc_deployment_hostname_suffix }}"
    port: 443
    # Inside the admin secret. There are two must fields
    admin_secret_name: "{{ meta.name }}-workspace-aae-app-engine-admin-secret"
    #-----------------------------------------------------------------------
    # The app engine admin Secret template will be
    #-----------------------------------------------------------------------
    # apiVersion: v1
    # stringData:
    #   AE_DATABASE_PWD: "<Your database password>"
    #   AE_DATABASE_USER: "<Your database username>"
    #   REDIS_PASSWORD: "<Your Redis server password>"
    # kind: Secret
    # metadata:
    #   name: icp4adeploy-workspace-aae-app-engine-admin-secret
    # type: Opaque
    #-----------------------------------------------------------------------
    # Designate an existing LDAP user for the Application Engine admin user.
    # This user ID should be in the IBM Business Automation Navigator administrator role, as specified as appLoginUsername in the Navigator secret.
    # This user should also belong to the User Management Service (UMS) Teams admin group or the UMS Teams Administrators team.
    # If not, follow the instructions in "Completing post-deployment tasks for Business Automation Studio and Application Engine" in the IBM Documentation to add it to the Navigator Administrator role and UMS team server admin group.
    admin_user: <Required>
    external_tls_secret:
    external_connection_timeout: 90s
    replica_size: 1
    # data_persistence is for Business Automation Application Data Persistence(ae_data_persistence).
    # If you are using pattern mode, the shared_configuration.sc_deployment_patterns contains value and sc_optional_components contains ae_data_persistence, then you do not need input any value to data_persistence.enable, it is enabled by default.
    # If you are using non-pattern mode, you can set data_persistence.enable to true to enable it.
    # Notes: ae_data_persistence is not supported in starter pattern mode and when AE is as playback server
    data_persistence:
        enable:
        ## If ae_data_persistence is enabled. Then you must input one CPE object store name. If you keep the default object store configuration. Then the default name filled should be AEOS.
        object_store_name: "AEOS"
    ## When the database type is Db2 you can set this to false, must be set to true when the database type is Oracle, PostgreSQL.
    use_custom_jdbc_drivers: false
    service_type: Route
    autoscaling:
      enabled: false
      max_replicas: 5
      min_replicas: 2
      target_cpu_utilization_percentage: 80
    server_identifier: ""
    database:
      # AE Database host name or IP when the database type is Db2, PostgreSQL, SQLSERVER.
      host: <Required>
      # AE Database name when the database type is Db2, PostgreSQL, SQLSERVER.
      #Provide the database name for runtime application engine use
      #Please pay attention that if you selected authoring environment also.
      #The database used by playback server and this one should be different
      name: <Required>
      # AE database port number when the database type is Db2, PostgreSQL, SQLSERVER.
      port: <Required>
      ## If you setup Db2 HADR or PostgreSQL, SQLSERVER Connection Fail-over and want to use it, you need to configure alternative_host and alternative_port, or else, leave is as blank.
      ## If more than one server name is specified, delimit the server names with commas (,). The number of values that is specified for alternative_host must match the number of values that is specified for alternative_port.
      alternative_host:
      alternative_port:
      ## Only Db2, Oracle, PostgreSQL, SQLSERVER are supported.
      type: db2
      ## Required only when the database type is Oracle, both ssl and non-ssl. The format must be purely Oracle descriptor like (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=<your database host/IP>)(PORT=<your database port>))(CONNECT_DATA=(SERVICE_NAME=<your Oracle service name>))).
      oracle_url_without_wallet_directory:
      enable_ssl: true
      ## Required only when type is Oracle and enable_ssl is true. The format must be purely oracle descriptor. SSO wallet directory must be specified and fixed to (MY_WALLET_DIRECTORY=/shared/resources/oracle/wallet).
      oracle_url_with_wallet_directory:
      ## Required only when enable_ssl is true, when the database type is Db2, Oracle, SQLSERVER or PostgreSQL
      db_cert_secret_name: <Required>
      ## Required only when type is oracle and enable_ssl is true.
      oracle_sso_wallet_secret_name:
      ## Optional. If it is empty, the DBASB is default when the database type is Db2 or PostgreSQL; the AE_DATABASE_USER set in the admin_secret_name is default when the database type is Oracle and SQLSERVER.
      current_schema: DBASB
      initial_pool_size: 1
      max_pool_size: 100
      max_lru_cache_size: 1000
      max_lru_cache_age: 600000
      dbcompatibility_max_retries: 30
      dbcompatibility_retry_interval: 10
      ## The persistent volume claim for custom JDBC Drivers if using the custom JDBC drivers is enabled(use_custom_jdbc_drivers is true).
      custom_jdbc_pvc:
    log_level:
      node: info
      browser: 2
    content_security_policy:
      enable: false
      whitelist:
      frame_ancestor:
    env:
      max_size_lru_cache_rr: 1000
      server_env_type: development
      purge_stale_apps_interval: 86400000
      # Number of preview-only automation application must be more to trigger purge,
      apps_threshold: 100
      # Age of preview-only automation application since publish to be stale in milliseconds
      stale_threshold: 172800000
      # Number of preview-only automation services must be more to trigger purge,
      service_threshold: 100
      # Age of preview-only automation service since publish to be stale in milliseconds
      service_stale_threshold: 172800000
      # Service socket connection timeout in milliseconds
      connection_timeout: 120000
      uv_thread_pool_size: 40
      # Set custom enviroment varaible on app engine pods
      custom_environment_variables:
      # # example entry for setting timezone on pod
      # - key: TZ
      #   value: Europe/Warsaw
    max_age:
      auth_cookie: "900000"
      csrf_cookie: "3600000"
      static_asset: "2592000"
      hsts_header: "2592000"
    probe:
      liveness:
        failure_threshold: 5
        initial_delay_seconds: 60
        period_seconds: 10
        success_threshold: 1
        timeout_seconds: 180
      readiness:
        failure_threshold: 5
        initial_delay_seconds: 10
        period_seconds: 10
        success_threshold: 1
        timeout_seconds: 180
    #-----------------------------------------------------------------------
    # If you want better HA experience.
    # - Set the session.use_external_store to true
    # - Fill in your redis server information
    #-----------------------------------------------------------------------
    redis:
      # Your external redis host/ip
      host:
      # Your external redis port
      port: '6379'
      ttl: 1800
      # If your redis enabled TLS connection set this to true
      # You should add redis server CA certificate in tls_trust_list or trusted_certificate_list
      tls_enabled: false
      # If you are using Redis V6 and above with username fill in this field.
      # Otherwise leave this field as empty
      username:
    resource_ae:
      limits:
        cpu: 500m
        memory: 1Gi
      requests:
        cpu: 300m
        memory: 256Mi
    resource_init:
      limits:
        cpu: 500m
        memory: 256Mi
      requests:
        cpu: 100m
        memory: 128Mi
    session:
      check_period: "3600000"
      duration: "1800000"
      max: "10000"
      resave: "false"
      rolling: "true"
      save_uninitialized: "false"
      #-----------------------------------------------------------------------
      # If you want better HA experience.
      # - Set the session.use_external_store to true
      # - Fill in your redis server information
      #-----------------------------------------------------------------------
      use_external_store: "false"
    tls:
      tls_trust_list: []
    # If you want to make the replicate size more than 1 for this cluster. Then you must enable the shared storage
    share_storage:
      enabled: true
      # If you create the PV manually. Then please provide the PVC name bind here
      pvc_name:
      auto_provision:
        enabled: true
        # Required if you enabled the auto provision
        storage_class:
        size: 20Gi
    log_storage:
      enabled: true
      pvc_name: 'cp4a-shared-log-pvc'
      log_file_size: '20M'
      log_rotate_size: 5
      auto_provision:
        enabled: true
        # By default it will reuse the operator shared log pvc. If you assgined other name
        # And enabled the auto provision. We will provision that with fast storage class by default
        # If you want to adjust that please fill in this value.
        storage_class: ""
        size: '5Gi'
