
###############################################################################
##
##Licensed Materials - Property of IBM
##
##(C) Copyright IBM Corp. 2021. All Rights Reserved.
##
##US Government Users Restricted Rights - Use, duplication or
##disclosure restricted by GSA ADP Schedule Contract with IBM Corp.
##
###############################################################################
apiVersion: icp4a.ibm.com/v1
kind: ICP4ACluster
metadata:
  name: icp4adeploy
  labels:
    app.kubernetes.io/instance: ibm-dba
    app.kubernetes.io/managed-by: ibm-dba
    app.kubernetes.io/name: ibm-dba
    release: 21.0.3
spec:
  ##########################################################################
  ## This section contains the shared configuration for all CP4A components #
  ##########################################################################
  appVersion: 21.0.3

  ## MUST exist, used to accept ibm license, valid value only can be "accept"
  ibm_license: ""

  shared_configuration:

    ## FileNet Content Manager (FNCM) license and possible values are: user, non-production, and production.
    ## This value could be different from the other licenses in the CR.
    sc_deployment_fncm_license: "<Required>"

    ## Use this parameter to specify the license for the CP4A deployment and
    ## the possible values are: non-production and production and if not set, the license will
    ## be defaulted to production.  This value could be different from the other licenses in the CR.
    sc_deployment_license: "<Required>"

    ## The deployment context, which has a default value of "CP4A".  Unless you are instructed to change this value or 
    ## know the reason to change this value, please leave the default value.
    sc_deployment_context: "CP4A"

    ## All CP4A components must use/share the image_pull_secrets to pull images.
    image_pull_secrets:
    - admin.registrykey

    ## All CP4A components must use/share the same docker image repository.  For example, if IBM Entitled Registry is used, then
    ## it should be "cp.icr.io".  Otherwise, it will be a local docker registry.
    sc_image_repository: cp.icr.io

    ## Used to sign all CP4A internal certificates for internal services communications. In most cases, this value should not be changed.
    ## All CP4A components must use/share the root_ca_secret in order for integration.
    root_ca_secret: icp4a-root-ca

    ## Optional: You can specify a profile size for CloudPak - valid values are small, medium, large - default is small.
    sc_deployment_profile_size: "small"

    ## Shared custom TLS secret which will be used to sign all external routes if defined.
    ## If this is not defined, all external routes will be signed with `root_ca_secret`
    ## From 21.0.3 on, this parameter only apply for non-OCP deployment.  In an OCP deployment, all external traffics are going through Zen's front door and custom TLS certifcates must  be integrated with Zen's front door.  
    ## Please refer to https://www.ibm.com/docs/en/cloud-paks/1.0?topic=cc-updating-custom-hostname-tls-secret-by-using-configmap for more information.
    external_tls_certificate_secret:

    ## CP4A patterns or capabilities to be deployed.  This CR represents the "document_processing" pattern (aka IBM Autoation Document Processing),
    ## which includes the following required/mandatory components:
    ##   - Development env:
    ##     - cds, cdra, cpds, viewone, Common Git Gateway (git-service and mongodb), cpe, navigator-sso, graphql;
    ##     - backend, redis, rabbitmq;
    ##     - extraction (callerapi, pdfprocess, utf8process, ocr-extraction);
    ##     - processing (postprocessing, setup, classifyprocess-classify, processing-extraction, updatefiledetail);
    ##     - natural_language_extractor; deep learning;
    ##     - ums;
    ##     - bastudio, jms, solution-server-helmjob-db, solution-server, dba-etcd;
    ##   - Runtime env:
    ##     - cpds, viewone, cpe, navigator-sso, graphql;
    ##     - backend, redis, rabbitmq;
    ##     - extraction (callerapi, pdfprocess, utf8process, ocr-extraction);
    ##     - processing (postprocessing, setup, classifyprocess-classify, processing-extraction, updatefiledetail);
    ##     - natural_language_extractor;
    ##     - ums;
    ##     - solution-server-helmjob-db, solution-server, dba-etcd;
    sc_deployment_patterns: document_processing

    ## The optional components to be installed if listed here.  This is normally populated by the User script based on input from the user.
    ## The optional components are:
    ##   - document_processing_designer (indicates the deployment is a development environment)
    ##   - document_processing_runtime (indicates the deployment is a runtime environment)
    ##   - cmis, css, es, tm
    ##   - ae_data_persistence (Business Automation Application Data Persistence)
    sc_optional_components: ae_data_persistence

    ## The deployment type as selected by the user.  Possible values are: Starter and Production.
    sc_deployment_type: Production

    ## For "document_processing" (ADP), you have the option to select CPE "full storage" or "limited storage" (free).
    ## By default, ADP is deployed with CPE "full storage" (sc_cpe_limited_storage: false).  Set sc_cpe_limited_storage
    ## to "true" if you want to use CPE "limited storage" license
    sc_cpe_limited_storage: false

    ## Specify the RunAsUser for the security context of the pod.  This is usually a numeric value that corresponds to a user ID.
    ## For non-OCP (e.g., CNCF platforms such as AWS, GKE, etc), this parameter is optional. It is not supported on OCP and ROKS.
    sc_run_as_user:

    ## For ROKS, this is used to enable the creation of ingresses. The default value is "false", which routes will be created.
    sc_ingress_enable: false

    ## The platform to be deployed specified by the user.  Possible values are: OCP and other.  This is normally populated by the User script
    ## based on input from the user.
    sc_deployment_platform:

    ## For OCP, this is used to create route, you should input a valid hostname in the required field.


    ## If the root certificate authority (CA) key of the external service is not signed by the operator root CA key, provide the TLS certificate of
    ## the external service to the component's truststore.
    trusted_certificate_list: []


    ## Shared encryption key secret name that is used for Workflow or Workstream Services and Process Federation Server integration.
    ## This secret is also used by Workflow and BAStudio to store AES encryption key.
    encryption_key_secret: ibm-iaws-shared-key-secret

    ## Enable/disable ECM (FNCM) / BAN initialization (e.g., creation of P8 domain, creation/configuration of object stores,
    ## creation/configuration of CSS servers, and initialization of Navigator (ICN)).  If the "initialize_configuration" section
    ## is defined with the required parameters in the CR (below) and sc_content_initialization is set to "true" (or the parameter doesn't exist), then the initialization will occur.
    ## However, if sc_content_initialization is set to "false", then the initialization will not occur (even with the "initialize_configuration" section defined)
    sc_content_initialization: false

    ## OR
    ## If you want to enable the initialize for a specific product for ECM (FNCM) / BAN, you will need to use
    ## these fields instead.  Otherwise, use the default sc_content_initialization: false
    # sc_content_initialization:
    #  cpe: false
    #  css: false
    #  ban: false


    ## Enable/disable the ECM (FNCM) / BAN verification (e.g., creation of test folder, creation of test document,
    ## execution of CBR search, and creation of Navigator demo repository and desktop).  If the "verify_configuration"
    ## section is defined in the CR, then that configuration will take precedence overriding this parameter.  Note that if you are upgrading or
    ## migrating, set this parameter to "false" since the env has been previously verified.
    sc_content_verification: false
    ## OR
    ## If you want to enable the verification for a specific product for ECM (FNCM) / BAN, you will need to use
    ## these fields instead.  Otherwise, use the default sc_content_verification: false
    # sc_content_verification:
    #  cpe: false
    #  css: false
    #  ban: false

    ## On OCP 3.x and 4.x, the User script will populate these three (3) parameters based on your input for "production" deployment.
    ## If you manually deploying without using the User script, then you would provide the different storage classes for the slow, medium
    ## and fast storage parameters below.  If you only have 1 storage class defined, then you can use that 1 storage class for all 3 parameters.
    ## sc_block_storage_classname is for Zen, Zen requires/recommends block storage (RWO) for metastoreDB
    storage_configuration:
      sc_slow_file_storage_classname: "<Required>"
      sc_medium_file_storage_classname: "<Required>"
      sc_fast_file_storage_classname: "<Required>"
      sc_block_storage_classname: "<Required>"

  ## The beginning section of LDAP configuration for CP4A
  ldap_configuration:
    ## The possible values are: "IBM Security Directory Server" or "Microsoft Active Directory"
    lc_selected_ldap_type: "<Required>"

    ## The name of the LDAP server to connect
    lc_ldap_server: "<Required>"

    ## The port of the LDAP server to connect.  Some possible values are: 389, 636, etc.
    lc_ldap_port: "<Required>"

    ## The LDAP bind secret for LDAP authentication.  The secret is expected to have ldapUsername and ldapPassword keys.  Refer to Knowledge Center for more info.
    lc_bind_secret: ldap-bind-secret

    ## The LDAP base DN.  For example, "dc=example,dc=com", "dc=abc,dc=com", etc
    lc_ldap_base_dn: "<Required>"

    ## Enable SSL/TLS for LDAP communication. Refer to Knowledge Center for more info.
    lc_ldap_ssl_enabled: true

    ## The name of the secret that contains the LDAP SSL/TLS certificate.
    lc_ldap_ssl_secret_name: "<Required>"

    ## The LDAP user name attribute. Semicolon-separated list that must include the first RDN user distinguished names. One possible value is "*:uid" for TDS and "user:sAMAccountName" for AD. Refer to Knowledge Center for more info.
    lc_ldap_user_name_attribute: "<Required>"

    ## The LDAP user display name attribute. One possible value is "cn" for TDS and "sAMAccountName" for AD. Refer to Knowledge Center for more info.
    lc_ldap_user_display_name_attr: "<Required>"

    ## The LDAP group base DN.  For example, "dc=example,dc=com", "dc=abc,dc=com", etc
    lc_ldap_group_base_dn: "<Required>"

    ## The LDAP group name attribute.  One possible value is "*:cn" for TDS and "*:cn" for AD. Refer to Knowledge Center for more info.
    lc_ldap_group_name_attribute: "*:cn"

    ## The LDAP group display name attribute.  One possible value for both TDS and AD is "cn". Refer to Knowledge Center for more info.
    lc_ldap_group_display_name_attr: "cn"

    ## The LDAP group membership search filter string.  One possible value is "(|(&(objectclass=groupofnames)(member={0}))(&(objectclass=groupofuniquenames)(uniquemember={0})))" for TDS
    ## and "(&(cn=%v)(objectcategory=group))" for AD.
    lc_ldap_group_membership_search_filter: "<Required>"

    ## The LDAP group membership ID map.  One possible value is "groupofnames:member" for TDS and "memberOf:member" for AD.
    lc_ldap_group_member_id_map: "<Required>"

    ## The User script will uncomment the section needed based on user's input from User script.  If you are deploying without the User script,
    ## uncomment the necessary section (depending if you are using Active Directory (ad) or Tivoli Directory Service (tds)) accordingly.
    # ad:
    #   lc_ad_gc_host: "<Required>"
    #   lc_ad_gc_port: "<Required>"
    #   lc_user_filter: "(&(sAMAccountName=%v)(objectcategory=user))"
    #   lc_group_filter: "(&(cn=%v)(objectcategory=group))"
    # tds:
    #   lc_user_filter: "(&(cn=%v)(objectclass=person))"
    #   lc_group_filter: "(&(cn=%v)(|(objectclass=groupofnames)(objectclass=groupofuniquenames)(objectclass=groupofurls)))"

    ## This section allows to enhance the ldap configuration for the UMS SCIM capability. If lc_user_filter or lc_group_filter cannot handle a custom LDAP filter for user or group searches this section should be enabled.
    ## optional: enables the liberty ldapEntityType configuration and disables the usage of lc_user_filter, lc_group_filter, lc_ldap_group_member_id_map, lc_ldap_user_name_attribute and lc_ldap_group_name_attribute in the UMS capabilities.
    ## for detailed information about the ldapEntityType, loginProperty and groupProperties  parameters please see the liberty documentation: https://www.ibm.com/docs/en/was-liberty/nd?topic=configuration-ldapregistry
    ## default is false
    lc_use_ldap_entity_type:
    ## optional: only used if lc_use_ldap_entity_type is true
    ## default is uid
    lc_ldap_login_property:
    ## optional: only used if lc_use_ldap_entity_type is true
    ## the defaults depends on the lc_selected_ldap_type
    lc_ldap_entity_type_user:
      object_class:
      search_base:
      searchfilter:
    ## optional: only used if lc_use_ldap_entity_type is true
    ## the defaults depends on the lc_selected_ldap_type
    lc_ldap_entity_type_group:
      object_class:
      search_base:
      searchfilter:
    ## optional: only used if lc_use_ldap_entity_type is true
    ## the defaults depends on the lc_selected_ldap_type
    lc_ldap_group_properties:
      # member_attribute:
        # The name of the member. Required if member_attribute is set
        # name:
        # The name of the object class. Required member_attribute is set
        # object_class:
        ## the scope options are: all, direct, nested
        # scope:
      #membership_attribute:
        # The name of the membership. Required if membership_attribute is set
        # name:
        ## the scope options are: all, direct, nested
        # scope:


  ## User script should only uncomment this section if External Share if selected as an optional component.
  ## If you are deploying without the User script, uncomment the necessary section (depending
  ## if you are using Active Directory (ad) or Tivoli Directory Service (tds)) accordingly.
  # ext_ldap_configuration:
  #   lc_selected_ldap_type: "<Required>"
  #   lc_ldap_server: "<Required>"
  #   lc_ldap_port: "<Required>"
  #   lc_bind_secret: ldap-bind-secret
  #   lc_ldap_base_dn: "<Required>"
  #   lc_ldap_ssl_enabled: true
  #   lc_ldap_ssl_secret_name: "<Required>"
  #   lc_ldap_user_name_attribute: "<Required>"
  #   lc_ldap_user_display_name_attr: "<Required>"
  #   lc_ldap_group_base_dn: "<Required>"
  #   lc_ldap_group_name_attribute: "<Required>"
  #   lc_ldap_group_display_name_attr: "cn"
  #   lc_ldap_group_membership_search_filter: "<Required>"
  #   lc_ldap_group_member_id_map: "<Required>"

    ## User script will uncomment the section needed based on user's input from User script.
    ## If you are deploying without the User script, uncomment the necessary section (depending
    ## if you are using Active Directory (ad) or Tivoli Directory Service (tds)) accordingly.
    # ad:
    ## This is the Global Catalog port for the LDAP
    #   lc_ad_gc_host: "<Required>"
    #   lc_ad_gc_port: "<Required>"
    #   lc_user_filter: "(&(sAMAccountName=%v)(objectcategory=user))"
    #   lc_group_filter: "(&(cn=%v)(objectcategory=group))"
    # tds:
    #   lc_user_filter: "(&(cn=%v)(objectclass=person))"
    #   lc_group_filter: "(&(cn=%v)(|(objectclass=groupofnames)(objectclass=groupofuniquenames)(objectclass=groupofurls)))"

   ## Uncomment this section if you have OpenId Connect providers.
    # open_id_connect_providers: "<Required>"
    ## Set the provider name that is for your redirect url.
    #- provider_name: "<Required>"
       ## Set the display name for the sign in button in navigator.
    #  display_name: "Single Sign on"
       ## Enter your oidc secret names here for cpe, nav external share and graphql.
       ## Not all are required depending on you deployment.
    #  client_oidc_secret:
    #    es: "" # Points to a secret with client_id and client_secret in that format.
    #    nav: "" # Points to a secret with client_id and client_secret in that format.
    #    cpe: "" # Points to a secret with client_id and client_secret in that format.
    #    graphql: "" # Points to a secret with client_id and client_secret in that format.
    #  issuer_identifier: ""
       ## REQUIRED PROPERTIES AND VALUES which are common
       ## If not set will be set to the defaults.
    #  response_type: "code"
    #  scope: "openid email profile"
    #  map_identity_to_registry_user: "false"
    #  authn_session_disabled: "false"
    #  inbound_propagation: "supported"
    #  https_required: "true"
    #  validation_method: "introspect"
    #  disable_ltpa_cookie: "true"
    #  signature_algorithm: "RS256"
    #  user_identifier: "sub" # sub for ums and ibm id, email for google
    #  unique_user_identifier: "sub" # sub for ums and ibm id, email for google
    #  user_identity_to_create_subject: "sub" # sub for ums and ibm id, email for google
       ##
       ## Uncomment out discovery_endpoint_url for Google or UMS IdP.
       ##
    #  discovery_endpoint_url:
       ##
       ## Optional parameters
       ##
    #    authorization_endpoint_url: ""
    #    token_endpoint_url: ""
    #    validation_endpoint_url: ""
    #    trust_alias_name: "secrent name you created"
    #    disables_iss_checking: "true"
    #    jwk_client_oidc_secret:
    #      es: "" # Points to a secret with client_id and client_secret in that format.
    #      nav: "" # Points to a secret with client_id and client_secret in that format.
    #      cpe: "" # Points to a secret with client_id and client_secret in that format.
    #      graphql: ""  # Points to a secret with client_id and client_secret in that format.
    #    token_reuse: "true"
       ##
       ## User defined parameters.
       ## If you do not see a parameter that is needed for you OpenId Connect provider.
       ## You are able to defined in this section has a key value pair separated by the delimeter `:`
       ## If you want to change the default delimeter, add `DELIM=<NEW_DELIMETER>` infront of your
       ## key value pair. Ex: 'DELIM=;myKey;myValue'.  In this example, the new delimeter is `;` and
       ## the key value pair is set to `myKey;myValue` instead of `myKey:myValue`.
       ##
    #    oidc_ud_param:
    #    - 'DELIM=;myKey;myValue'
    #    - "myKey2:myValue2"
    #    - "myKey3:myValue3"

  ## The beginning section of database configuration for CP4A
  datasource_configuration:
    ## The dc_ssl_enabled parameter is used to support database connection over SSL for DB2/Oracle/PostgreSQL.
    dc_ssl_enabled: true
    ## The database_precheck parameter is used to enable or disable CPE/Navigator database connection check.
    ## If set to "true", then CPE/Navigator database connection check will be enabled.
    ## if set to "false", then CPE/Navigator database connection check will not be enabled.
   # database_precheck: true
    ## The database configuration for the GCD datasource for CPE
    dc_gcd_datasource:
      ## Provide the database type from your infrastructure.  The possible values are "db2" or "db2HADR" or "oracle" or "postgresql".
      dc_database_type: "<Required>"
      ## The GCD non-XA datasource name.  The default value is "FNGCDDS".
      dc_common_gcd_datasource_name: "FNGCDDS"
      ## The GCD XA datasource name. The default value is "FNGCDDSXA".
      dc_common_gcd_xa_datasource_name: "FNGCDDSXA"
      ## Provide the database server name or IP address of the database server.
      database_servername: "<Required>"
      ## Provide the name of the database for the GCD for CPE.  For example: "GCDDB"
      database_name: "<Required>"
      ## Provide the database server port.  For Db2, the default is "50000".  For Oracle, the default is "1521"
      database_port: "<Required>"
      ## The name of the secret that contains the DB2/Oracle/PostgreSQL SSL certificate.
      database_ssl_secret_name: "<Required>"
      ## If the database type is Oracle, provide the Oracle DB connection string.  For example, "jdbc:oracle:thin:@//<oracle_server>:1521/orcl"
      dc_oracle_gcd_jdbc_url: "<Required>"

      ## If the database type is Db2 HADR, then complete the rest of the parameters below.
      ## Provide the database server name or IP address of the standby database server.
      dc_hadr_standby_servername: "<Required>"
      ## Provide the standby database server port.  For Db2, the default is "50000".
      dc_hadr_standby_port: "<Required>"
      ## Provide the validation timeout.  If not preference, keep the default value.
      dc_hadr_validation_timeout: 15
      ## Provide the retry internal.  If not preference, keep the default value.
      dc_hadr_retry_interval_for_client_reroute: 15
      ## Provide the max # of retries.  If not preference, keep the default value.
      dc_hadr_max_retries_for_client_reroute: 3
      ## Connection manager for a data source.
      connection_manager:
        ## Minimum number of physical connections to maintain in the pool.
        min_pool_size: 0
        ## Maximum number of physical connections for a pool.
        max_pool_size: 50
        ## Amount of time a connection can be unused or idle until it can be discarded during pool maintenance, if doing so does not reduce the pool below the minimum size.
        max_idle_time: 1m
        ## Amount of time between runs of the pool maintenance thread.
        reap_time: 2m
        ## Specifies which connections to destroy when a stale connection is detected in a pool.
        purge_policy: EntirePool

    dc_os_datasources:
    ## The data source configuration for DEVOS1 object store.
    ## Provide the database type from your infrastructure.  The possible values are "db2" or "db2HADR" or "oracle" or "postgresql".  This should be the same as the GCD configuration above.
    - dc_database_type: "<Required>"
      ## For the "document_processing" pattern, the following parameters below MUST remain unchanged and have the default value:
      ##   dc_os_label: "devos1"
      ##   dc_common_os_datasource_name: "DEVOS1DS"
      ##   dc_common_os_xa_datasource_name: "DEVOS1DSXA"

      ## When creating the ibm-fncm-secret, the OS secret must be defined as:
      ##   --from-literal=adposDBUsername="<your os db username>" --from-literal=adposDBPassword="<your os db password>"
      ## If you have multiple object stores, then you need to define multiple datasource sections starting at "dc_database_type" element after this section.
      ## Each dc_os_label shoudl be different (e.g., dc_os_label: "os1", dc_os_label: "os2", dc_os_label: "os3", etc).
      ## This label must match the OS secret you define in ibm-fncm-secret.
      ## For example, if you define dc_os_label: "os1", then your OS secret must be defined as:
      ## --from-literal=os1DBUsername="<your os db username>" --from-literal=os1DBPassword="<your os db password>"
      ## If you don't define dc_os_label, then your secret will be defined as:
      ## --from-literal=osDBUsername="<your os db username>" --from-literal=osDBPassword="<your os db password>".
      ## If all the object store databases share the same username and password, then dc_os_label value should be the same in all the datasource sections.
      dc_os_label: "devos1"
      ## The OS1 non-XA datasource name.  The default value is "DEVOS1DS".
      dc_common_os_datasource_name: "DEVOS1DS"
      ## The OS1 XA datasource name.  The default value is "DEVOS1DSXA".
      dc_common_os_xa_datasource_name: "DEVOS1DSXA"
      ## Provide the database server name or IP address of the database server.  This should be the same as the
      ## GCD configuration above.
      database_servername: "<Required>"
      ## Provide the name of the database for the object store 1 for CPE.  For example: "DEVOS1DB"
      database_name: "<Required>"
      ## Provide the database server port.  For Db2, the default is "50000".  For Oracle, the default is "1521"
      database_port: "<Required>"
      ## The name of the secret that contains the DB2/Oracle/PostgreSQL SSL certificate.
      database_ssl_secret_name: "<Required>"
      ## If the database type is Oracle, provide the Oracle DB connection string.  For example, "jdbc:oracle:thin:@//<oracle_server>:1521/orcl"
      dc_oracle_os_jdbc_url: "<Required>"
      ######################################################################################
      ## If the database type is "Db2HADR", then complete the rest of the parameters below.
      ## Otherwise, remove or comment out the rest of the parameters below.
      ######################################################################################
      dc_hadr_standby_servername: "<Required>"
      ## Provide the standby database server port.  For Db2, the default is "50000".
      dc_hadr_standby_port: "<Required>"
      ## Provide the validation timeout.  If not preference, keep the default value.
      dc_hadr_validation_timeout: 15
      ## Provide the retry internal.  If not preference, keep the default value.
      dc_hadr_retry_interval_for_client_reroute: 15
      ## Provide the max # of retries.  If not preference, keep the default value.
      dc_hadr_max_retries_for_client_reroute: 3
      ## Connection manager for a data source.
      connection_manager:
        ## Minimum number of physical connections to maintain in the pool.
        min_pool_size: 0
        ## Maximum number of physical connections for a pool.
        max_pool_size: 50
        ## Amount of time a connection can be unused or idle until it can be discarded during pool maintenance, if doing so does not reduce the pool below the minimum size.
        max_idle_time: 1m
        ## Amount of time between runs of the pool maintenance thread.
        reap_time: 2m
        ## Specifies which connections to destroy when a stale connection is detected in a pool.
        purge_policy: EntirePool

    ## The data source configuration for AEOS object store.
    - dc_database_type: "<Required>"
      ## For the "document_processing" pattern, the following parameters below MUST remain unchanged and have the default value:
      ##   dc_os_label: "aeos"
      ##   dc_common_os_datasource_name: "AEOS"
      ##   dc_common_os_xa_datasource_name: "AEOSXA"
      ## When creating the ibm-fncm-secret, the OS secret must be defined as:
      ##   --from-literal=adposDBUsername="<your os db username>" --from-literal=adposDBPassword="<your os db password>"
      ## If you have multiple object stores, then you need to define multiple datasource sections starting at "dc_database_type" element after this section.
      ## Each dc_os_label shoudl be different (e.g., dc_os_label: "os1", dc_os_label: "os2", dc_os_label: "os3", etc).
      ## This label must match the OS secret you define in ibm-fncm-secret.
      ## For example, if you define dc_os_label: "os1", then your OS secret must be defined as:
      ## --from-literal=os1DBUsername="<your os db username>" --from-literal=os1DBPassword="<your os db password>"
      ## If you don't define dc_os_label, then your secret will be defined as:
      ## --from-literal=osDBUsername="<your os db username>" --from-literal=osDBPassword="<your os db password>".
      ## If all the object store databases share the same username and password, then dc_os_label value should be the same in all the datasource sections.
      dc_os_label: "aeos"
      ## The OS1 non-XA datasource name.  The default value is "AEOS".
      dc_common_os_datasource_name: "AEOS"
      ## The OS1 XA datasource name.  The default value is "AEOSXA".
      dc_common_os_xa_datasource_name: "AEOSXA"
      ## Provide the database server name or IP address of the database server.  This should be the same as the
      ## GCD configuration above.
      database_servername: "<Required>"
      ## Provide the name of the database for the object store 1 for CPE.  For example: "AEOSDB"
      database_name: "<Required>"
      ## Provide the database server port.  For Db2, the default is "50000".  For Oracle, the default is "1521"
      database_port: "<Required>"
      ## The name of the secret that contains the DB2/Oracle/PostgreSQL SSL certificate.
      database_ssl_secret_name: "<Required>"
      ## If the database type is Oracle, provide the Oracle DB connection string.  For example, "jdbc:oracle:thin:@//<oracle_server>:1521/orcl"
      dc_oracle_os_jdbc_url: "<Required>"
      ######################################################################################
      ## If the database type is "Db2HADR", then complete the rest of the parameters below.
      ## Otherwise, remove or comment out the rest of the parameters below.
      ######################################################################################
      dc_hadr_standby_servername: "<Required>"
      ## Provide the standby database server port.  For Db2, the default is "50000".
      dc_hadr_standby_port: "<Required>"
      ## Provide the validation timeout.  If not preference, keep the default value.
      dc_hadr_validation_timeout: 15
      ## Provide the retry internal.  If not preference, keep the default value.
      dc_hadr_retry_interval_for_client_reroute: 15
      ## Provide the max # of retries.  If not preference, keep the default value.
      dc_hadr_max_retries_for_client_reroute: 3
      ## Connection manager for a data source.
      connection_manager:
        ## Minimum number of physical connections to maintain in the pool.
        min_pool_size: 0
        ## Maximum number of physical connections for a pool.
        max_pool_size: 50
        ## Amount of time a connection can be unused or idle until it can be discarded during pool maintenance, if doing so does not reduce the pool below the minimum size.
        max_idle_time: 1m
        ## Amount of time between runs of the pool maintenance thread.
        reap_time: 2m
        ## Specifies which connections to destroy when a stale connection is detected in a pool.
        purge_policy: EntirePool

    ## The database configuration for ICN (Navigator) - aka BAN (Business Automation Navigator)
    dc_icn_datasource:
      ## Provide the database type from your infrastructure.  The possible values are "db2" or "db2HADR" or "oracle" or "postgresql".  This should be the same as the
      ## GCD and object store configuration above.
      dc_database_type: "<Required>"
      ## Provide the ICN datasource name.  The default value is "ECMClientDS".
      dc_common_icn_datasource_name: "ECMClientDS"
      database_servername: "<Required>"
      ## Provide the database server port.  For Db2, the default is "50000".  For Oracle, the default is "1521"
      database_port: "<Required>"
      ## Provide the name of the database for ICN (Navigator).  For example: "ICNDB"
      database_name: "<Required>"
      ## The name of the secret that contains the DB2/Oracle/PostgreSQL SSL certificate.
      database_ssl_secret_name: "<Required>"
      ## If the database type is Oracle, provide the Oracle DB connection string.  For example, "jdbc:oracle:thin:@//<oracle_server>:1521/orcl"
      dc_oracle_icn_jdbc_url: "<Required>"
      ######################################################################################
      ## If the database type is "Db2HADR", then complete the rest of the parameters below.
      ## Otherwise, remove or comment out the rest of the parameters below.
      ######################################################################################
      dc_hadr_standby_servername: "<Required>"
      ## Provide the standby database server port.  For Db2, the default is "50000".
      dc_hadr_standby_port: "<Required>"
      ## Provide the validation timeout.  If not preference, keep the default value.
      dc_hadr_validation_timeout: 15
      ## Provide the retry internal.  If not preference, keep the default value.
      dc_hadr_retry_interval_for_client_reroute: 15
      ## Provide the max # of retries.  If not preference, keep the default value.
      dc_hadr_max_retries_for_client_reroute: 3
      ## Connection manager for a data source.
      connection_manager:
        ## Minimum number of physical connections to maintain in the pool.
        min_pool_size: 0
        ## Maximum number of physical connections for a pool.
        max_pool_size: 50
        ## Amount of time a connection can be unused or idle until it can be discarded during pool maintenance, if doing so does not reduce the pool below the minimum size.
        max_idle_time: 1m
        ## Amount of time between runs of the pool maintenance thread.
        reap_time: 2m
        ## Specifies which connections to destroy when a stale connection is detected in a pool.
        purge_policy: EntirePool

    ## The database configuration for UMS (User Management Service)
    dc_ums_datasource:
      ## Provide the datasource configuration for oauth
      ## Possible dc_ums_oauth_type values are "derby" for test only and "db2", "oracle", "sqlserver" and "postgresql" for production.
      ## This configuration should be the same as the other datasource configuration in the dc_ums_datasource section.
      ## db2 with HADR is automatically activated if dc_ums_oauth_alternate_hosts and dc_ums_oauth_alternate_ports are set.
      ## For Oracle RAC, specify the host name of the SCAN listener as the value of the dc_ums_oauth_host parameter
      dc_ums_oauth_type: "<Required>"
      ## Provide the database server name or IP address of the database server.
      dc_ums_oauth_host: "<Required>"
      ## Provide the database server port.  For Db2, the default is "50000".  For Oracle, the default is "1521". For MSSQL, the default is "1433"- For PostgreSQL, the default is "5432".
      dc_ums_oauth_port: "<Required>"
      ## Provide the name of the database for UMS.  For example: "UMSDB"
      dc_ums_oauth_name: "<Required>"
      dc_ums_oauth_schema: OAuthDBSchema
      dc_ums_oauth_ssl: true
      dc_ums_oauth_ssl_secret_name: "<Required>"
      ## For "oracle", "sqlserver" and "postgresql" provide the names of the driver files
      dc_ums_oauth_driverfiles:
      ## For db2 HADR only
      dc_ums_oauth_alternate_hosts:
      dc_ums_oauth_alternate_ports:

      ## Provide the datasource configuration for the teamserver
      ## Possible dc_ums_teamserver_type values are "derby" for test only and "db2", "oracle", "sqlserver" and "postgresql" for production.
      ## This configuration should be the same as the other datasource configuration in the dc_ums_datasource section.
      ## db2 with HADR is automatically activated if dc_ums_teamserver_alternate_hosts and dc_ums_teamserver_alternate_ports are set.
      ## For Oracle RAC, specify the host name of the SCAN listener as the value of the dc_ums_teamserver_host parameter
      dc_ums_teamserver_type: "<Required>"
      dc_ums_teamserver_host: "<Required>"
      ## Provide the database server port.  For Db2, the default is "50000".  For Oracle, the default is "1521". For MS SQL, the default is "1433"- For PostgreSQL, the default is "5432".
      dc_ums_teamserver_port: "<Required>"
      ## Provide the name of the database for UMS teamserver.  For example: "UMSDB"
      dc_ums_teamserver_name: "<Required>"
      dc_ums_teamserver_ssl: true
      dc_ums_teamserver_ssl_secret_name: "<Required>"
      ## For "oracle", "sqlserver" and "postgresql" provide the names of the driver files
      dc_ums_teamserver_driverfiles:
      ## For db2 HADR only
      dc_ums_teamserver_alternate_hosts:
      dc_ums_teamserver_alternate_ports:

    ## The database configuration for ACA (Content Analyzer)
    dc_ca_datasource:
      ## Provide the database type from your infrastructure.  The possible values are "db2" or "db2HADR"
      dc_database_type: "<Required>"
      ## Provide  the hostname of the primary DB2 server in this variable and IF your DB2 hostname is not resolvable by DNS THEN  provide the corresponding IP address.
      database_servername: "<Required>"
      ## Provide the name of the BASE database for ACA.  For example: "BASECA"
      database_name: "<Required>"
      ## Provide the names of the TENANT databases for ACA.
      tenant_databases:
      - "<Required>"
      ## Provide the database server port.  For Db2, the default is "50000".
      database_port: "<Required>"
      ## Enable SSL/TLS for database communication. Refer to Knowledge Center for more info.
      dc_database_ssl_enabled: true
      ######################################################################################
      ## If the database type is "Db2HADR", then complete the rest of the parameters below.
      ## Otherwise, remove or comment out the rest of the parameters below.
      ######################################################################################
      ## The `database_servername` field above must be in the form of fully qualify DNS name if DB2 HADR is used.
      ## Provide the standby database server name and if your standby database server name cannot be resolvable by DNS, then provide the corresponding IP address for the `dc_hadr_standby_ip` parameter below.
      dc_hadr_standby_servername: "<Required>"
      ## Provide the standby database server port.  For Db2, the default is "50000".
      dc_hadr_standby_port: "<Required>"
      ## Provide the validation timeout.  If not preference, keep the default value.
      dc_hadr_validation_timeout: 15
      ## Provide the retry internal.  If not preference, keep the default value.
      dc_hadr_retry_interval_for_client_reroute: 15
      ## Provide the max # of retries.  If not preference, keep the default value.
      dc_hadr_max_retries_for_client_reroute: 3
      ## Provide the primary database server IP address if database_servername cannot be resolved by DNS.
      database_ip: ""
      ## Provide the standby database server IP address if dc_hadr_standby_servername cannot be resolved by DNS.
      dc_hadr_standby_ip: ""

   ## Monitor setting
 # monitoring_configuration:
  #   mon_metrics_writer_option: 4
  #   mon_enable_plugin_pch: false
  #   mon_enable_plugin_mbean: false
  #   collectd_plugin_write_graphite_host: localhost
  #   collectd_plugin_write_graphite_port: 2003
  #   collectd_interval: 10
  #   collectd_disable_host_monitoring: false
  #   collectd_plugin_write_prometheus_port: 9103

  # # Logging setting
  # logging_configuration:
  #   mon_log_parse: false
  #   mon_log_service_endpoint: localhost:5044
  #   private_logging_enabled: false
  #   logging_type: default
  #   mon_log_path: /path_to_extra_log

  ########################################################################
  ########      IBM FileNet Content Manager configuration         ########
  ########################################################################
  ecm_configuration:
    ## FNCM secret that contains GCD DB user name and password, Object Store DB user name and password,
    ## LDAP user and password, CPE username and password, keystore password, and LTPA passs, etc.
    fncm_secret_name: ibm-fncm-secret

    ## By default all the components create ingress and routes with required annotations. In case any custom annotation is needed for the environment provide below.
    #    route_ingress_annotations:
    #      - haproxy.router.openshift.io/balance: roundrobin
    route_ingress_annotations:

    # Optional: You can specify a profile size for FNCM if different from CloudPak (see shared_configuration.sc_deployment_profile_size).  In other words,
    # you can override "shared_configuration.sc_deployment_profile_size" with "deployment_profile_size" defined here.
    # The valid values are small, medium, large - default is small.  The resources in this file are reflecting a "small" profile.
    #deployment_profile_size: "small"

    ####################################
    ## Start of configuration for CPE ##
    ####################################
    cpe:
      ## The architecture of the cluster.  This is the default for Linux on x86 and should not be changed.
      arch:
        amd64: "3 - Most preferred"

      ## The number of replicas or pods to be deployed.  The default is 2 replica and for high availability in a production env,
      ## it is recommended to have 2 or more.
      replica_count: 2

      ## This is the image repository and tag that correspond to image registry, which is where the image will be pulled.
      image:
        ## The default repository is the IBM Entitled Registry.
        repository: cp.icr.io/cp/cp4a/fncm/cpe
        tag: ga-558-p8cpe-if001

        ## This will override the image pull policy in the shared_configuration.
        pull_policy: IfNotPresent

      ## Logging for workloads.  This is the default setting.
      log:
       format: json

      ## The initial resources (CPU, memory) requests and limits.  If more resources are needed,
      ## make the changes here to meet your requirement.
      resources:
        requests:
          cpu: 500m
          memory: 512Mi
        limits:
          cpu: 1
          memory: 3072Mi

      ## By default "Autoscaling" is enabled with the following settings with a minimum of 2 replca and a maximum of 3 replicas.  Change
      ## this settings to meet your requirement.
      auto_scaling:
        enabled: false
        max_replicas: 3
        min_replicas: 2
        ## This is the default cpu percentage before autoscaling occurs.
        target_cpu_utilization_percentage: 80

      ## Below are the default CPE Production settings.  Make the necessary changes as you see fit.  Refer to Knowledge Center documentation for details.
      cpe_production_setting:
        time_zone: Etc/UTC

        ## The initial use of available memory.
        jvm_initial_heap_percentage: 18
        ## The maximum percentage of available memory to use.
        jvm_max_heap_percentage: 33

        ## Use this "jvm_customize_options" parameter to specify JVM arguments using comma separation. For example, if you want to set the following JVM arguments:
        ##  -Dmy.test.jvm.arg1=123
        ##  -Dmy.test.jvm.arg2=abc
        ##  -XX:+SomeJVMSettings
        ##  -XshowSettings:vm"
        ## Then set the following: jvm_customize_options="-Dmy.test.jvm.arg1=123,-Dmy.test.jvm.arg2=abc,-XX:+SomeJVMSettings,-XshowSettings:vm"
        jvm_customize_options:

        ## Default JNDI name for GCD for non-XA data source
        gcd_jndi_name: FNGCDDS
        ## Default JNDI name for GCD for XA data source
        gcd_jndixa_name: FNGCDDSXA
        license_model: FNCM.PVUNonProd

        # The license must be set to "accept" in order for the component to install.  This is the default value.
        license: accept

        # Enable/disable FIPS (default value is "false")
        disable_fips: false

      ## Enable/disable monitoring where metrics can be sent to Graphite or scraped by Prometheus
      monitor_enabled: false
      ## Enable/disable logging where logs can be sent to Elasticsearch.
      logging_enabled: false

      ## By default, the plugin for Graphite is enable to emit container metrics.
      collectd_enable_plugin_write_graphite: false

      ## Persistent Volume Claims for CPE.  If the storage_configuration in the shared_configuration is configured,
      ## the Operator will create the PVC using the names below.
      datavolume:
        existing_pvc_for_cpe_cfgstore: "cpe-cfgstore"
        existing_pvc_for_cpe_logstore: "cpe-logstore"
        existing_pvc_for_cpe_filestore: "cpe-filestore"
        existing_pvc_for_cpe_icmrulestore: "cpe-icmrulesstore"
        existing_pvc_for_cpe_textextstore: "cpe-textextstore"
        existing_pvc_for_cpe_bootstrapstore: "cpe-bootstrapstore"
        existing_pvc_for_cpe_fnlogstore: "cpe-fnlogstore"

      ## Default values for both rediness and liveness probes.  Modify these values to meet your requirements.
      probe:
        readiness:
          initial_delay_seconds: 120
          period_seconds: 5
          timeout_seconds: 10
          failure_threshold: 6
        liveness:
          initial_delay_seconds: 600
          period_seconds: 5
          timeout_seconds: 5
          failure_threshold: 6

      ## Only use this parameter if you want to override the image_pull_secrets setting in the shared_configuration above.
      image_pull_secrets:
        name: "admin.registrykey"
    ####################################
    ## Start of configuration for CSS ##
    ####################################
    css:
      ## The architecture of the cluster.  This is the default for Linux on x86 and should not be changed.
      arch:
        amd64: "3 - Most preferred"

      ## The number of replicas or pods to be deployed.  The default is 2 replica and for high availability in a production env,
      ## it is recommended to have 2 or more.
      replica_count: 2

      ## This is the image repository and tag that correspond to image registry, which is where the image will be pulled.
      image:
        ## The default repository is the IBM Entitled Registry.
        repository: cp.icr.io/cp/cp4a/fncm/css
        tag: ga-558-p8css-if001

        ## This will override the image pull policy in the shared_configuration.
        pull_policy: IfNotPresent

      ## Logging for workloads.  This is the default setting.
      log:
        format: json

      ## The initial resources (CPU, memory) requests and limits.  If more resources are needed,
      ## make the changes here to meet your requirement.
      resources:
        requests:
          cpu: 500m
          memory: 512Mi
        limits:
          cpu: 1
          memory: 4096Mi

      ## CSS Production setting
      css_production_setting:
        ## The maximum percentage of available memory to use.
        jvm_max_heap_percentage: 50

        # The license must be set to "accept" in order for the component to install.  This is the default value.
        license: accept

        ## Uncomment icc section below to enable IBM Content Collector P8 Content Search Services Support.  Refer to Knowledge Center documentation for details.
        # icc:
        #   icc_enabled: true
        #   icc_secret_name: "ibm-icc-secret"
        #   p8domain_name: "P8DOMAIN"

      ## Enable/disable monitoring where metrics can be sent to Graphite or scraped by Prometheus
      monitor_enabled: false
      ## Enable/disable logging where logs can be sent to Elasticsearch.
      logging_enabled: false
      ## By default, the plugin for Graphite is enable to emit container metrics.
      collectd_enable_plugin_write_graphite: false

      ## Persistent Volume Claims for CSS.  If the storage_configuration in the shared_configuration is configured,
      ## the Operator will create the PVC using the names below.
      datavolume:
        existing_pvc_for_css_cfgstore: "css-cfgstore"
        existing_pvc_for_css_logstore: "css-logstore"
        existing_pvc_for_css_tmpstore: "css-tempstore"
        existing_pvc_for_index: "css-indexstore"
        existing_pvc_for_css_customstore: "css-customstore"

      ## Default values for both rediness and liveness probes.  Modify these values to meet your requirements.
      probe:
        readiness:
          initial_delay_seconds: 60
          period_seconds: 5
          timeout_seconds: 10
          failure_threshold: 6
        liveness:
          initial_delay_seconds: 180
          period_seconds: 5
          timeout_seconds: 5
          failure_threshold: 6
      ## Only use this parameter if you want to override the image_pull_secrets setting in the shared_configuration above.
      image_pull_secrets:
        name: "admin.registrykey"

    #####################################
    ## Start of configuration for CMIS ##
    #####################################
    cmis:
      ## The architecture of the cluster.  This is the default for Linux on x86 and should not be changed.
      arch:
        amd64: "3 - Most preferred"

      ## The number of replicas or pods to be deployed.  The default is 2 replica and for high availability in a production env,
      ## it is recommended to have 2 or more.
      replica_count: 2

      ## This is the image repository and tag that correspond to image registry, which is where the image will be pulled.
      image:
        ## The default repository is the IBM Entitled Registry.
        repository: cp.icr.io/cp/cp4a/fncm/cmis
        tag: ga-306-cmis-la105

        ## This will override the image pull policy in the shared_configuration.
        pull_policy: IfNotPresent

      ## Logging for workloads.  This is the default setting.
      log:
        format: json

      ## The initial resources (CPU, memory) requests and limits.  If more resources are needed,
      ## make the changes here to meet your requirement.
      resources:
        requests:
          cpu: 500m
          memory: 256Mi
        limits:
          cpu: 1
          memory: 1536Mi

      ## By default "Autoscaling" is enabled with the following settings with a minimum of 2 replca and a maximum of 3 replicas.  Change
      ## this settings to meet your requirement.
      auto_scaling:
        enabled: false
        max_replicas: 3
        min_replicas: 2
        ## This is the default cpu percentage before autoscaling occurs.
        target_cpu_utilization_percentage: 80

      ## Below are the default CMIS Production settings.  Make the necessary changes as you see fit.  Refer to Knowledge Center documentation for details.
      cmis_production_setting:
        ## By default, this parameter is set by the Operator using the CPE service endpoint (e.g., "http://{{ meta.name }}-cpe-svc:9080/wsi/FNCEWS40MTOM")
        cpe_url:

        time_zone: Etc/UTC

        ## The initial use of available memory.
        jvm_initial_heap_percentage: 40
        ## The maximum percentage of available memory to use.
        jvm_max_heap_percentage: 66

        ## Use this "jvm_customize_options" parameter to specify JVM arguments using comma separation. For example, if you want to set the following JVM arguments:
        ##  -Dmy.test.jvm.arg1=123
        ##  -Dmy.test.jvm.arg2=abc
        ##  -XX:+SomeJVMSettings
        ##  -XshowSettings:vm"
        ## Then set the following: jvm_customize_options="-Dmy.test.jvm.arg1=123,-Dmy.test.jvm.arg2=abc,-XX:+SomeJVMSettings,-XshowSettings:vm"
        jvm_customize_options:

        ## Enable/disable FIPS (default value is "false")
        disable_fips: false

        ## Enable/disable Websphere Security
        ws_security_enabled: false

        # Enable/disable the content-stream of the Private Working Copy should be copied from the Document that was checked out.
        checkout_copycontent: true
        # The default value for the optional maxItems input argument on paging-related services.
        default_maxitems: 25

        # Enable/disable whether ChoiceLists will be cached once for all users.
        cvl_cache: true
        secure_metadata_cache: false

        # Enable/disalbe hidden P8 domain properties should appear in CMIS type definitions and folder or document instance data.
        filter_hidden_properties: true

        # Timeout in seconds for the queries that specify timeout.
        querytime_limit: 180

        # If true, then a faster response time for REST next line. If false, the next link for REST will re-issue query.
        resumable_queries_forrest: true

        # Specifies whether to escape characters that are not valid for XML unicode as specified by the XML 1.0 standard.
        escape_unsafe_string_characters: false

        # Limits the maximum allowable Web Service SOAP message request size.
        max_soap_size: 180

        # Enable/disable the printing of the full stack trace in the response.
        print_pull_stacktrace: false

        # Configures the sequence in which CMIS tries to identify objects (folder or document first).
        folder_first_search: false

        # To ignore the reading or writing contents in root folder, set this parameter to true.
        ignore_root_documents: false

        # Enable/disable the support type mutability.
        supporting_type_mutability: false

        # The license must be set to "accept" in order for the component to install.  This is the default value.
        license: accept

      ## Enable/disable monitoring where metrics can be sent to Graphite or scraped by Prometheus
      monitor_enabled: false
      ## Enable/disable logging where logs can be sent to Elasticsearch.
      logging_enabled: false

      ## By default, the plugin for Graphite is enable to emit container metrics.
      collectd_enable_plugin_write_graphite: false

      ## Persistent Volume Claims for CMIS.  If the storage_configuration in the shared_configuration is configured,
      ## the Operator will create the PVC using the names below.
      datavolume:
        existing_pvc_for_cmis_cfgstore: "cmis-cfgstore"
        existing_pvc_for_cmis_logstore: "cmis-logstore"

      ## Default values for both rediness and liveness probes.  Modify these values to meet your requirements.
      probe:
        readiness:
          initial_delay_seconds: 90
          period_seconds: 5
          timeout_seconds: 10
          failure_threshold: 6
        liveness:
          initial_delay_seconds: 180
          period_seconds: 5
          timeout_seconds: 5
          failure_threshold: 6

      ## Only use this parameter if you want to override the image_pull_secrets setting in the shared_configuration above.
      image_pull_secrets:
        name: "admin.registrykey"

    ########################################
    ## Start of configuration for GraphQL ##
    ########################################
    graphql:
      ## The architecture of the cluster.  This is the default for Linux on x86 and should not be changed.
      arch:
        amd64: "3 - Most preferred"

      ## The number of replicas or pods to be deployed.  The default is 2 replica and for high availability in a production env,
      ## it is recommended to have 2 or more.
      replica_count: 2

      ## This is the image repository and tag that correspond to image registry, which is where the image will be pulled.
      image:
        ## The default repository is the IBM Entitled Registry.
        repository: cp.icr.io/cp/cp4a/fncm/graphql
        tag: ga-558-p8cgql-if001

        ## This will override the image pull policy in the shared_configuration.
        pull_policy: IfNotPresent

      ## Logging for workloads.  This is the default setting.
      log:
        format: json

      ## The initial resources (CPU, memory) requests and limits.  If more resources are needed,
      ## make the changes here to meet your requirement.
      resources:
        requests:
          cpu: 500m
          memory: 512Mi
        limits:
          cpu: 1
          memory: 1536Mi

      ## By default "Autoscaling" is enabled with the following settings with a minimum of 2 replca and a maximum of 3 replicas.  Change
      ## this settings to meet your requirement.
      auto_scaling:
        enabled: false
        min_replicas: 2
        max_replicas: 3
        ## This is the default cpu percentage before autoscaling occurs.
        target_cpu_utilization_percentage: 80

      ## Below are the default CMIS Production settings.  Make the necessary changes as you see fit.  Refer to Knowledge Center documentation for details.
      graphql_production_setting:
        time_zone: Etc/UTC

        ## The initial use of available memory.
        jvm_initial_heap_percentage: 40
        ## The maximum percentage of available memory to use.
        jvm_max_heap_percentage: 66

        ## Use this "jvm_customize_options" parameter to specify JVM arguments using comma separation. For example, if you want to set the following JVM arguments:
        ##  -Dmy.test.jvm.arg1=123
        ##  -Dmy.test.jvm.arg2=abc
        ##  -XX:+SomeJVMSettings
        ##  -XshowSettings:vm"
        ## Then set the following: jvm_customize_options="-Dmy.test.jvm.arg1=123,-Dmy.test.jvm.arg2=abc,-XX:+SomeJVMSettings,-XshowSettings:vm"
        jvm_customize_options:

        license_model: FNCM.PVUNonProd

        # The license must be set to "accept" in order for the component to install.  This is the default value.
        license: accept

        enable_graph_iql: false

      ## Enable/disable monitoring where metrics can be sent to Graphite or scraped by Prometheus
      monitor_enabled: false
      ## Enable/disable logging where logs can be sent to Elasticsearch.
      logging_enabled: false

      ## By default, the plugin for Graphite is enable to emit container metrics.
      collectd_enable_plugin_write_graphite: false

      ## Persistent Volume Claims for GraphQL.  If the storage_configuration in the shared_configuration is configured,
      ## the Operator will create the PVC using the names below.
      datavolume:
        existing_pvc_for_graphql_cfgstore: "graphql-cfgstore"
        existing_pvc_for_graphql_logstore: "graphql-logstore"

      ## Default values for both rediness and liveness probes.  Modify these values to meet your requirements.
      probe:
        readiness:
          initial_delay_seconds: 120
          period_seconds: 5
          timeout_seconds: 10
          failure_threshold: 6
        liveness:
          initial_delay_seconds: 600
          period_seconds: 5
          timeout_seconds: 5
          failure_threshold: 6
      ## Only use this parameter if you want to override the image_pull_secrets setting in the shared_configuration above.
      image_pull_secrets:
        name: "admin.registrykey"

    ###############################################
    ## Start of configuration for External Share ##
    ###############################################
    es:
      ## The architecture of the cluster.  This is the default for Linux on x86 and should not be changed.
      arch:
        amd64: "3 - Most preferred"

      ## The number of replicas or pods to be deployed.  The default is 2 replica and for high availability in a production env,
      ## it is recommended to have 2 or more.
      replica_count: 2

      ## This is the image repository and tag that correspond to image registry, which is where the image will be pulled.
      image:
        ## The default repository is the IBM Entitled Registry.
        repository: cp.icr.io/cp/cp4a/fncm/extshare
        tag: ga-3011-es-if003

        ## This will override the image pull policy in the shared_configuration.
        pull_policy: IfNotPresent

      ## The initial resources (CPU, memory) requests and limits.  If more resources are needed,
      ## make the changes here to meet your requirement.
      resources:
        requests:
          cpu: 500m
          memory: 512Mi
        limits:
          cpu: 1
          memory: 1536Mi

      ## By default "Autoscaling" is enabled with the following settings with a minimum of 2 replca and a maximum of 3 replicas.  Change
      ## this settings to meet your requirement.
      auto_scaling:
        enabled: false
        min_replicas: 2
        max_replicas: 3
        ## This is the default cpu percentage before autoscaling occurs.
        target_cpu_utilization_percentage: 80

      ## Below are the default External Share Production settings.  Make the necessary changes as you see fit.  Refer to Knowledge Center documentation for details.
      es_production_setting:
        time_zone: Etc/UTC

        ## The initial use of available memory.
        jvm_initial_heap_percentage: 40
        ## The maximum percentage of available memory to use.
        jvm_max_heap_percentage: 66

        jvm_customize_options:
        license_model: FNCM.PVUNonProd

        # The license must be set to "accept" in order for the component to install.  This is the default value.
        license: accept
        allowed_origins:

      ## Enable/disable monitoring where metrics can be sent to Graphite or scraped by Prometheus
      monitor_enabled: false
      ## Enable/disable logging where logs can be sent to Elasticsearch.
      logging_enabled: false

      ## By default, the plugin for Graphite is enable to emit container metrics.
      collectd_enable_plugin_write_graphite: false


      ## Persistent Volume Claims for External Share.  If the storage_configuration in the shared_configuration is configured,
      ## the Operator will create the PVC using the names below.
      datavolume:
        existing_pvc_for_es_cfgstore: "es-cfgstore"
        existing_pvc_for_es_logstore: "es-logstore"

      ## Default values for both rediness and liveness probes.  Modify these values to meet your requirements.
      probe:
        readiness:
          initial_delay_seconds: 180
          period_seconds: 5
          timeout_seconds: 10
          failure_threshold: 6
        liveness:
          initial_delay_seconds: 600
          period_seconds: 5
          timeout_seconds: 5
          failure_threshold: 6
      ## Only use this parameter if you want to override the image_pull_secrets setting in the shared_configuration above.
      image_pull_secrets:
        name: "admin.registrykey"
    #############################################
    ## Start of configuration for Task Manager ##
    #############################################
    tm:
      ## The architecture of the cluster.  This is the default for Linux on x86 and should not be changed.
      arch:
        amd64: "3 - Most preferred"

      ## The number of replicas or pods to be deployed.  The default is 1 replica and for high availability in a production env,
      ## it is recommened to have 2 or more.
      replica_count: 2

      ## This is the image repository and tag that correspond to image registry, which is where the image will be pulled.
      image:
        ## The default repository is the IBM Entitled Registry.
        repository: cp.icr.io/cp/cp4a/fncm/taskmgr
        tag: ga-3011-tm-if003

        ## This will override the image pull policy in the shared_configuration.
        pull_policy: IfNotPresent

      ## The initial resources (CPU, memory) requests and limits.  If more resources are needed,
      ## make the changes here to meet your requirement.
      resources:
        requests:
          cpu: 500m
          memory: 512Mi
        limits:
          cpu: 1
          memory: 1536Mi

      ## By default "Autoscaling" is disabled with the following settings with a minimum of 2 replca and a maximum of 3 replicas.  Change
      ## this settings to meet your requirement.
      auto_scaling:
        enabled: false
        max_replicas: 3
        min_replicas: 2
        ## This is the default cpu percentage before autoscaling occurs.
        target_cpu_utilization_percentage: 80

      ## Below are the default TM Production settings.  Make the necessary changes as you see fit.  Refer to Knowledge Center documentation for details.
      tm_production_setting:
        time_zone: Etc/UTC

        ## The initial use of available memory.
        jvm_initial_heap_percentage: 40
        ## The maximum percentage of available memory to use.
        jvm_max_heap_percentage: 66

        ## Use this "jvm_customize_options" parameter to specify JVM arguments using comma separation. For example, if you want to set the following JVM arguments:
        ##  -Dmy.test.jvm.arg1=123
        ##  -Dmy.test.jvm.arg2=abc
        ##  -XX:+SomeJVMSettings
        ##  -XshowSettings:vm"
        ## Then set the following: jvm_customize_options="-Dmy.test.jvm.arg1=123,-Dmy.test.jvm.arg2=abc,-XX:+SomeJVMSettings,-XshowSettings:vm"
        jvm_customize_options: "-Dcom.ibm.ecm.task.StartUpListener.defaultLogLevel=FINE"
        license: accept

        ## All users/groups belong to one of three roles (Admin, User, or Auditor) that are specific to Task Manager.
        ## Each role takes a list of users/groups (e.g., groups: [taskAdmins, taskAdmins2]).  Refer to Knowledge Center documentation for details.
        # security_roles_to_group_mapping:
        #   task_admins:
        #     groups: [taskAdmins]
        #     users: []
        #   task_users:
        #     groups: [taskUsers]
        #     users: []
        #   task_auditors:
        #     groups: [taskAuditors]
        #     users: []

      ## Enable/disable monitoring where metrics can be sent to Graphite or scraped by Prometheus
      monitor_enabled: false
      ## Enable/disable logging where logs can be sent to Elasticsearch.
      logging_enabled: false

      ## By default, the plugin for Graphite is enable to emit container metrics.
      collectd_enable_plugin_write_graphite: false

      ## Persistent Volume Claims for Task Manager (TM).  If the storage_configuration in the shared_configuration is configured,
      ## the Operator will create the PVC using the names below.
      datavolume:
        existing_pvc_for_tm_cfgstore: "tm-cfgstore"
        existing_pvc_for_tm_logstore: "tm-logstore"
        existing_pvc_for_tm_pluginstore: "tm-pluginstore"

      ## Default values for both rediness and liveness probes.  Modify these values to meet your requirements.
      probe:
        readiness:
          initial_delay_seconds: 120
          period_seconds: 10
          timeout_seconds: 10
          failure_threshold: 6
        liveness:
          initial_delay_seconds: 600
          period_seconds: 10
          timeout_seconds: 5
          failure_threshold: 6

      ## Only use this parameter if you want to override the image_pull_secrets setting in the shared_configuration above.
      image_pull_secrets:
        name: "admin.registrykey"

    #############################################
    ##                                         ##
    ##   IBM Automation Document Processing    ##
    ##                                         ##
    #############################################
    document_processing:
      ## Optional: You can specify a profile size for Document_processing if different from CloudPak - valid values are small,medium,large - default is small.
      ## Resources in this file are reflecting small profile ones.
      #deployment_profile_size: "small"

      ##############################################################
      ## Start of configuration for Mongo DB      ##
      ##############################################################
      ## Set this parameter to false if you don't want Operator to deploy Mongo DB, and you want to use your own existing Mongo DB

      deploy_mongo: true
      mongo:
        ## The architecture of the cluster.  This is the default for Linux on x86 and should not be changed.
        arch:
          amd64: "3 - Most preferred"
        ## For MongoDB deployed by CP4A, replica_count is only supported with "1" due the version of MongoDB that is being deployed (non-HA).
        ##  Customers can deploy their own MongoDB and comment out this entire section.
        # replica_count: 1
        ## This is the image repository and tag that correspond to image registry, which is where the image will be pulled.
        image:
        ## The default repository is the IBM Entitled Registry.
          repository: cp.icr.io/cp/cp4a/iadp/mongo
          tag: 4.2.17

          ## This will override the image pull policy in the shared_configuration.
          pull_policy: IfNotPresent

        ## The initial resources (CPU, memory) requests and limits.  If more resources are needed, make the changes here to meet your requirement.
        resources:
          requests:
            cpu: 500m
            memory: 256Mi
          limits:
            cpu: 1
            memory: 1024Mi

        ## Persistent Volume Claims for Mongo.  If the storage_configuration in the shared_configuration is configured,
        ## the Operator will create the PVC using the names below.
        datavolume:
          existing_pvc_for_mongo_datastore: "mongo-datastore"

        ## Default values for both rediness and liveness probes.  Modify these values to meet your requirements.
        probe:
          readiness:
            initial_delay_seconds: 90
            period_seconds: 5
            timeout_seconds: 10
            failure_threshold: 6
          liveness:
            initial_delay_seconds: 180
            period_seconds: 5
            timeout_seconds: 5
            failure_threshold: 6

      ##############################################################
      ## Start of configuration for Git Gateway      ##
      ##############################################################
      gitgateway:
        ## The architecture of the cluster.  This is the default for Linux on x86 and should not be changed.
        arch:
          amd64: "3 - Most preferred"
        ## The number of replicas or pods to be deployed.  The default is 2 replica and for high availability in a production env,
        ## it is recommened to have 2 or more.
        replica_count: 2
        ## This is the image repository and tag that correspond to image registry, which is where the image will be pulled.
        image:
        ## The default repository is the IBM Entitled Registry.
          repository: cp.icr.io/cp/cp4a/iadp/gitgateway
          tag: 21.0.3-IF007

          ## This will override the image pull policy in the shared_configuration.
          pull_policy: IfNotPresent

        ## The initial resources (CPU, memory) requests and limits.  If more resources are needed, make the changes here to meet your requirement.
        resources:
          requests:
            cpu: 500m
            memory: 512Mi
          limits:
            cpu: 1
            memory: 1024Mi
        ## By default "Autoscaling" is enabled with the following settings with a minimum of 2 replca and a maximum of 3 replicas.  Change this settings to meet your requirement.
        auto_scaling:
          enabled: true
          max_replicas: 3
          min_replicas: 2
          ## This is the default cpu percentage before autoscaling occurs.
          target_cpu_utilization_percentage: 80

        # Below are the default Git Gateway settings.  Make the necessary changes as you see fit.  Refer to Knowledge Center documentation for details.
        production_setting:
          git_gateway_timeout: 60000
          git_gateway_http_request_timeout: 60s

        ## Persistent Volume Claims for Mongo.  If the storage_configuration in the shared_configuration is configured,
        ## the Operator will create the PVC using the names below.
        datavolume:
          existing_pvc_for_gitgateway_datastore: "gitgateway-datastore"

        ## Default values for both rediness and liveness probes.  Modify these values to meet your requirements.
        probe:
          readiness:
            initial_delay_seconds: 90
            period_seconds: 5
            timeout_seconds: 10
            failure_threshold: 6
          liveness:
            initial_delay_seconds: 180
            period_seconds: 5
            timeout_seconds: 5
            failure_threshold: 6

      ##############################################################
      ## Start of configuration for Content Designer Service      ##
      ##############################################################
      cds:
        ## The architecture of the cluster.  This is the default for Linux on x86 and should not be changed.
        arch:
          amd64: "3 - Most preferred"
        ## The number of replicas or pods to be deployed.  The default is 2 replica and for high availability in a production env,
        ## it is recommened to have 2 or more.
        replica_count: 2
        ## This is the image repository and tag that correspond to image registry, which is where the image will be pulled.
        image:
        ## The default repository is the IBM Entitled Registry.
          repository: cp.icr.io/cp/cp4a/iadp/cds
          tag: 21.0.3-IF007

          ## This will override the image pull policy in the shared_configuration.
          pull_policy: IfNotPresent

        ## The initial resources (CPU, memory) requests and limits.  If more resources are needed, make the changes here to meet your requirement.
        resources:
          requests:
            cpu: 500m
            memory: 512Mi
          limits:
            cpu: 1
            memory: 1024Mi

        ## By default "Autoscaling" is enabled with the following settings with a minimum of 2 replca and a maximum of 3 replicas.  Change this settings to meet your requirement.
        auto_scaling:
          enabled: true
          max_replicas: 3
          min_replicas: 2
          ## This is the default cpu percentage before autoscaling occurs.
          target_cpu_utilization_percentage: 80

        # Below are the default CDS Production settings.  Make the necessary changes as you see fit.  Refer to Knowledge Center documentation for details.
        production_setting:
          jvm_customize_options:
          license: accept

        ## Enable/disable monitoring where metrics can be sent to Graphite or scraped by Prometheus
        monitor_enabled: false
        ## Enable/disable logging where logs can be sent to Elasticsearch.
        logging_enabled: false

        ## Persistent Volume Claim for CDS.  If the storage_configuration in the shared_configuration is configured,
        ## the Operator will create the PVC using the names below.
        datavolume:
          existing_pvc_for_cds_logstore: "cds-logstore"

        ## Default values for both rediness and liveness probes.  Modify these values to meet your requirements.
        probe:
          readiness:
            initial_delay_seconds: 90
            period_seconds: 5
            timeout_seconds: 10
            failure_threshold: 6
          liveness:
            initial_delay_seconds: 180
            period_seconds: 5
            timeout_seconds: 5
            failure_threshold: 6

      ##############################################################
      ## Start of configuration for Content Designer Repo API     ##
      ##############################################################
      cdra:
        ## The architecture of the cluster.  This is the default for Linux on x86 and should not be changed.
        arch:
          amd64: "3 - Most preferred"
        ## The number of replicas or pods to be deployed.  The default is 2 replica and for high availability in a production env,
        ## it is recommened to have 2 or more.
        replica_count: 2
        ## This is the image repository and tag that correspond to image registry, which is where the image will be pulled.
        image:
          ## The default repository is the IBM Entitled Registry.
          repository: cp.icr.io/cp/cp4a/iadp/cdra
          tag: 21.0.3-IF007

          ## This will override the image pull policy in the shared_configuration.
          pull_policy: IfNotPresent

        ## The initial resources (CPU, memory) requests and limits.  If more resources are needed,
        ## make the changes here to meet your requirement.
        resources:
          requests:
            cpu: 500m
            memory: 1024Mi
          limits:
            cpu: 1
            memory: 3072Mi

        ## By default "Autoscaling" is enabled with the following settings with a minimum of 2 replca and a maximum of 3 replicas.  Change this settings to meet your requirement.
        auto_scaling:
          enabled: true
          max_replicas: 3
          min_replicas: 2
          ## This is the default cpu percentage before autoscaling occurs.
          target_cpu_utilization_percentage: 80

        # Below are the default CDS Production settings.  Make the necessary changes as you see fit.  Refer to Knowledge Center documentation for details.
        production_setting:

          ## The initial use of available memory.
          jvm_initial_heap_percentage: 66

          ## The maximum percentage of available memory to use.
          jvm_max_heap_percentage: 66

          ## Use this "jvm_customize_options" parameter to specify JVM arguments using comma separation. For example, if you want to set the following JVM arguments:
          ##  -Dmy.test.jvm.arg1=123
          ##  -Dmy.test.jvm.arg2=abc
          ##  -XX:+SomeJVMSettings
          ##  -XshowSettings:vm"
          ## Then set the following: jvm_customize_options="-Dmy.test.jvm.arg1=123,-Dmy.test.jvm.arg2=abc,-XX:+SomeJVMSettings,-XshowSettings:vm"
          jvm_customize_options:
          license: accept

        ## Enable/disable monitoring where metrics can be sent to Graphite or scraped by Prometheus
        monitor_enabled: false
        ## Enable/disable logging where logs can be sent to Elasticsearch.
        logging_enabled: false

        ## By default, the plugin for Graphite is enable to emit container metrics.
        collectd_enable_plugin_write_graphite: false

        ## Persistent Volume Claims for CDRA.  If the storage_configuration in the shared_configuration is configured,
        ## the Operator will create the PVC using the names below.
        datavolume:
          existing_pvc_for_cdra_cfgstore: "cdra-cfgstore"
          existing_pvc_for_cdra_logstore: "cdra-logstore"

        ## Default values for both rediness and liveness probes.  Modify these values to meet your requirements.
        probe:
          readiness:
            initial_delay_seconds: 90
            period_seconds: 5
            timeout_seconds: 10
            failure_threshold: 6
          liveness:
            initial_delay_seconds: 180
            period_seconds: 5
            timeout_seconds: 5
            failure_threshold: 6

      #################################################################
      ## Start of configuration for Content Project Designer Service ##
      #################################################################
      cpds:
        ## The architecture of the cluster.  This is the default for Linux on x86 and should not be changed.
        arch:
          amd64: "3 - Most preferred"

        ## The number of replicas or pods to be deployed.  The default is 2 replica and for high availability in a production env,
        ## it is recommened to have 2 or more.
        replica_count: 2

        ## This is the image repository and tag that correspond to image registry, which is where the image will be pulled.
        image:
          ## The default repository is the IBM Entitled Registry.
          repository: cp.icr.io/cp/cp4a/iadp/cpds
          tag: 21.0.3-IF007

          ## This will override the image pull policy in the shared_configuration.
          pull_policy: IfNotPresent

        ## The initial resources (CPU, memory) requests and limits.  If more resources are needed,
        ## make the changes here to meet your requirement.
        resources:
          requests:
            cpu: 500m
            memory: 512Mi
          limits:
            cpu: 1
            memory: 3096Mi

        ## By default "Autoscaling" is enabled with the following settings with a minimum of 2 replca and a maximum of 3 replicas.  Change this settings to meet your requirement.
        auto_scaling:
          enabled: true
          max_replicas: 3
          min_replicas: 2
          ## This is the default cpu percentage before autoscaling occurs.
          target_cpu_utilization_percentage: 80

       ## Below are the default CDS Production settings.  Make the necessary changes as you see fit.  Refer to Knowledge Center documentation for details.
        production_setting:

         ## The initial use of available memory.
          jvm_initial_heap_percentage: 18

          ## The maximum percentage of available memory to use.
          jvm_max_heap_percentage: 33

          ## Use this "jvm_customize_options" parameter to specify JVM arguments using comma separation. For example, if you want to set the following JVM arguments:
          ##  -Dmy.test.jvm.arg1=123
          ##  -Dmy.test.jvm.arg2=abc
          ##  -XX:+SomeJVMSettings
          ##  -XshowSettings:vm"
          ## Then set the following: jvm_customize_options="-Dmy.test.jvm.arg1=123,-Dmy.test.jvm.arg2=abc,-XX:+SomeJVMSettings,-XshowSettings:vm"
          jvm_customize_options:
          license: accept

          ## The repository service url.
          ## For a development environment default url is
          ## https://{{ meta.name }}-cdra-svc:9443/cdapi
          ## For a runtime environment update this value to point to your
          ## development cdra environment.
          repo_service_url: "https://{{ meta.name }}-cdra-svc:9443/cdapi"

        ## Enable/disable monitoring where metrics can be sent to Graphite or scraped by Prometheus
        monitor_enabled: false
        ## Enable/disable logging where logs can be sent to Elasticsearch.
        logging_enabled: false


        ## Persistent Volume Claims for CPDS.  If the storage_configuration in the shared_configuration is configured,
        ## the Operator will create the PVC using the names below.
        datavolume:
          existing_pvc_for_cpds_cfgstore: "cpds-cfgstore"
          existing_pvc_for_cpds_logstore: "cpds-logstore"

        ## Default values for both rediness and liveness probes.  Modify these values to meet your requirements.
        probe:
          readiness:
            initial_delay_seconds: 90
            period_seconds: 5
            timeout_seconds: 10
            failure_threshold: 6
          liveness:
            initial_delay_seconds: 180
            period_seconds: 5
            timeout_seconds: 5
            failure_threshold: 6

      #################################################################
      ## Start of configuration for viewone (Viewer Service)         ##
      #################################################################
      viewone:
        ## The architecture of the cluster.  This is the default for Linux on x86 and should not be changed.
        arch:
          amd64: "3 - Most preferred"

        ## The number of replicas or pods to be deployed.  The default is 2 replica and for high availability in a production env,
        ## it is recommened to have 2 or more.
        replica_count: 2

        ## This is the image repository and tag that correspond to image registry, which is where the image will be pulled.
        image:
          ## The default repository is the IBM Entitled Registry.
          repository: cp.icr.io/cp/cp4a/iadp/viewone
          tag: 21.0.3-IF007

          ## This will override the image pull policy in the shared_configuration.
          pull_policy: IfNotPresent

        ## The initial resources (CPU, memory) requests and limits.  If more resources are needed,
        ## make the changes here to meet your requirement.
        resources:
          requests:
            cpu: 500m
            memory: 1024Mi
          limits:
            cpu: 1
            memory: 4096Mi

        ## By default "Autoscaling" is enabled with the following settings with a minimum of 2 replica and a maximum of 3 replicas.  Change this settings to meet your requirement.
        auto_scaling:
          enabled: true
          max_replicas: 3
          min_replicas: 2
          ## This is the default cpu percentage before autoscaling occurs.
          target_cpu_utilization_percentage: 80

        ## Below are the default ViewOne Production settings.  Make the necessary changes as you see fit.  Refer to Knowledge Center documentation for details.
        production_setting:

          ## Font sync interval
          font_sync_interval_min: 0

          ## Add env variable
          add_env_variables:

          ## The initial use of available memory.
          jvm_initial_heap_percentage: 40

          ## The maximum percentage of available memory to use.
          jvm_max_heap_percentage: 66

          ## Use this "jvm_customize_options" parameter to specify JVM arguments using comma separation. For example, if you want to set the following JVM arguments:
          ##  -Dmy.test.jvm.arg1=123
          ##  -Dmy.test.jvm.arg2=abc
          ##  -XX:+SomeJVMSettings
          ##  -XshowSettings:vm"
          ## Then set the following: jvm_customize_options="-Dmy.test.jvm.arg1=123,-Dmy.test.jvm.arg2=abc,-XX:+SomeJVMSettings,-XshowSettings:vm"
          jvm_customize_options:

        ## Enable/disable monitoring where metrics can be sent to Graphite or scraped by Prometheus
        monitor_enabled: false
        ## Enable/disable logging where logs can be sent to Elasticsearch.
        logging_enabled: false

        ## Persistent Volume Claims for ViewOne.  If the storage_configuration in the shared_configuration is configured,
        ## the Operator will create the PVC using the names below.
        datavolume:
          existing_pvc_for_viewone_cacherootstore: "viewone-cacherootstore"
          existing_pvc_for_viewone_docrepositoryrootstore: "viewone-docrepositoryrootstore"
          existing_pvc_for_viewone_workingpathstore: "viewone-workingpathstore"
          existing_pvc_for_viewone_externalresourcepathstore: "viewone-externalresourcepathstore"
          existing_pvc_for_viewone_logsstore: "viewone-logsstore"
          existing_pvc_for_viewone_customerfontsstore: "viewone-customerfontsstore"
          existing_pvc_for_viewone_configstore: "viewone-configstore"
        ## Default values for both rediness and liveness probes.  Modify these values to meet your requirements.
        probe:
          readiness:
            initial_delay_seconds: 90
            period_seconds: 5
            timeout_seconds: 10
            failure_threshold: 6
          liveness:
            initial_delay_seconds: 180
            period_seconds: 5
            timeout_seconds: 5
            failure_threshold: 6

  ########################################################################
  ########   IBM Business Automation Navigator configuration      ########
  ########################################################################
  navigator_configuration:
    ## Navigator secret that contains user credentials for LDAP and database
    ban_secret_name: ibm-ban-secret

    ## By default all the components create ingress and routes with required annotations. In case any custom annotation is needed for the environment provide below.
    #    route_ingress_annotations:
    #      - haproxy.router.openshift.io/balance: roundrobin
    route_ingress_annotations:

    # Optional: You can specify a profile size for FNCM if different from CloudPak (see shared_configuration.sc_deployment_profile_size).  In other words,
    # you can override "shared_configuration.sc_deployment_profile_size" with "deployment_profile_size" defined here.
    # The valid values are small, medium, large - default is small.  The resources in this file are reflecting a "small" profile.
    #deployment_profile_size: "small"

    ## The architecture of the cluster.  This is the default for Linux and should not be changed.
    arch:
      amd64: "3 - Most preferred"

    ## The number of replicas or pods to be deployed.  The default is 2 replica and for high availability in a production env,
    ## it is recommended to have 2 or more.
    replica_count: 2

    ## This is the image repository and tag that correspond to image registry, which is where the image will be pulled.
    image:
      ## The default repository is the IBM Entitled Registry
      repository: cp.icr.io/cp/cp4a/ban/navigator
      tag: ga-3011-icn-if003

      ## This will override the image pull policy in the shared_configuration.
      pull_policy: IfNotPresent

    ## Logging for workloads.  This is the default setting.
    log:
      format: json

    ## The initial resources (CPU, memory) requests and limits.  If more resources are needed,
    ## make the changes here to meet your requirement.
    resources:
      requests:
        cpu: 500m
        memory: 512Mi
      limits:
        cpu: 1
        memory: 1536Mi

    ## By default "Autoscaling" is enabled with the following settings with a minimum of 2 replca and a maximum of 3 replicas.  Change
    ## this settings to meet your requirement.
    auto_scaling:
      enabled: false
      max_replicas: 3
      min_replicas: 2
      ## This is the default cpu percentage before autoscaling occurs.
      target_cpu_utilization_percentage: 80

    ## send email
    java_mail:
      host: "fncm-exchange1.ibm.com"
      port: "25"
      sender: "MailAdmin@fncmexchange.com"
      ssl_enabled: false


    ## Below are the default ICN Production settings.  Make the necessary changes as you see fit.  Refer to Knowledge Center documentation for details.
    icn_production_setting:
      timezone: Etc/UTC

      ## The initial use of available memory.
      jvm_initial_heap_percentage: 40
      ## The maximum percentage of available memory to use.
      jvm_max_heap_percentage: 66

      ## Use this "jvm_customize_options" parameter to specify JVM arguments using comma separation. For example, if you want to set the following JVM arguments:
      ##  -Dmy.test.jvm.arg1=123
      ##  -Dmy.test.jvm.arg2=abc
      ##  -XX:+SomeJVMSettings
      ##  -XshowSettings:vm"
      ## Then set the following: jvm_customize_options="-Dmy.test.jvm.arg1=123,-Dmy.test.jvm.arg2=abc,-XX:+SomeJVMSettings,-XshowSettings:vm"
      jvm_customize_options:

      ## Enable/disable FIPS (default value is "false")
      disable_fips: false

      icn_jndids_name: ECMClientDS
      icn_schema: ICNDB
      icn_table_space: ICNDB
      allow_remote_plugins_via_http: false
      ## uncomment copy_files_to_war parameter to copy customized files into Navigator web application.
      ## The <custom-dir>/navigator_war_filesources.xml must be located in config volume mapping, which is /opt/ibm/wlp/usr/servers/defaultServer/configDropins/overrides
      # copy_files_to_war: <custom-dir>/navigator_war_filesources.xml

      ## The WalkMe URL references a WalkMe snippet.  This snippet is a piece of JavaScript code that allows WalkMe to be displayed in the application.
      ## Each WalkMe Editor account has a unique snippet code that can be accessed inside the Editor.
      #  walkme_url: https://cdn.walkme.com/users/4e7c687193414395aa0411837a9eee4b/test/walkme_4e7c687193414395aa0411837a9eee4b_https.js

    ## Default settings for monitoring
    monitor_enabled: false
    ## Default settings for logging
    logging_enabled: false

    ## Persistent Volume Claims for ICN.  If the storage_configuration in the shared_configuration is configured,
    ## the Operator will create the PVC using the names below.
    datavolume:
      existing_pvc_for_icn_cfgstore: "icn-cfgstore"
      existing_pvc_for_icn_logstore: "icn-logstore"
      existing_pvc_for_icn_pluginstore: "icn-pluginstore"
      existing_pvc_for_icnvw_cachestore: "icn-vw-cachestore"
      existing_pvc_for_icnvw_logstore: "icn-vw-logstore"
      existing_pvc_for_icn_aspera: "icn-asperastore"

    ## Default values for both rediness and liveness probes.  Modify these values to meet your requirements.
    probe:
      readiness:
        initial_delay_seconds: 120
        period_seconds: 5
        timeout_seconds: 10
        failure_threshold: 6
      liveness:
        initial_delay_seconds: 600
        period_seconds: 5
        timeout_seconds: 5
        failure_threshold: 6

    ## Only use this parameter if you want to override the image_pull_secrets setting in the shared_configuration above.
    image_pull_secrets:
      name: "admin.registrykey"

  ############################################################################
  ########   IBM Business Automation Content Analyzer configuration   ########
  ############################################################################
  ca_configuration:
    global:
      ## Optional setting for the deployment profile size for Content Analyzer.
      # Allowed values: "small", "medium", "large"
      # If set, this setting overrides the equivalent setting "shared_configuration.sc_deployment_profile_size".
      # If not set, the value of "shared_configuration.sc_deployment_profile_size" would be used. If that is not set, default is "small".
      # This setting only applies to the deployment profile size of Content Analyzer, not the other components.
      deployment_profile_size: small
      # The flag to indicate whether the OCP cluster is FIPS enabled or not (true or false).  Default will be false if blank
      enable_fips: false
## Route and Ingress annotations. For more information on the annotations, refer to https://docs.openshift.com/container-platform/4.6/networking/routes/route-configuration.html#nw-route-specific-annotations_route-configuration
## By default, Content Analyzer will predefine `haproxy.router.openshift.io/disable_cookies: 'true'`.
## The timeout will be set to 120s if not specified. The timeout can be overwritten by specifying a new timeout value in second (s).
      route_ingress_annotations:
      - haproxy.router.openshift.io/timeout: 150s
## Indicate whether to enable metrics for ACA.  True or false
      metrics: "true"
      ## The external tls certificate secret name for signing ACA certificates. It will take precedent over the shared_configuration.external_tls_certificate_secret when it's defined.
      external_tls_certificate_secret:
      arch: "amd64"
      # The database secret name created as part of the pre-req.  Default will be "aca-basedb" if blank.
      db_secret:
      # Global HPA auto scaling configuration. These parameters will take effect if the `auto_scaling` section under individual components are not defined. Once you define the auto_scaling section here, it will apply the same settings for all CA's subcomponents.
      # The min_replicas and max_replicas will be used if auto_scaling.enabled is true.
      auto_scaling:
        enabled: false
        target_cpu_utilization_percentage: 90
        min_replicas: 2
        max_replicas: 3
      image:
        repository: "cp.icr.io/cp/cp4a/iadp"
        tag: "21.0.3-IF007"
        pull_policy: "IfNotPresent"
## Overwrite the default SHA digest for Content Analyzer containers by providing the SHA for each containers below.  To use SHA digest, you must comment out the `tag` parameter or leave it blank and you must use entilement registry as the repository.
        processing_digest:
        natural_language_extractor_digest:
        extraction_digest:
        backend_digest:
        rabbitmq_digest:
        redis_digest:
        deep_learning:
      # The max of retrying for CA deployment verification task until all the pods are in Ready status. A delay of 20 seconds between each attempt.  Default will be 90 if blank
      retries: "90"
      # ACA configuration PVC setting
      configs:
        claimname: "sp-config-pvc"
        #Size of config PVC in GB
        size:
      # ACA log PVC setting
      logs:
        #  Number of log files to be kept before they will be rolled over.  Default is 20 if it's not defined.
        log_rotate_count: 20
        # Maximum size of log file.  Use `k` for KB , `m` for MB, and `g` GB
        log_file_max_size: "50m"
        claimname: "sp-log-pvc"
        log_level: "debug"
        #Size of log PVC in GB
        size:
      # ACA data PVC setting
      data:
        claimname: "sp-data-pvc"
        #Size of Data PVC in GB
        size:
      # Redis configuration
      redis:
        resources:
          limits:
            memory: "640Mi"
            cpu: "0.25"
        # Set 'replica_count' below to override the default number of pods (the default is based on the 'deployment_profile_size' parameter)   
        #replica_count: 2
      # RabbitMQ configuration.
      # memory_high_watermark is the memory threshold assigned to RabbitMQ.  It's recommended to be at 50% of the total memory of the RabbitMQ pod.
      rabbitmq:
        resources:
          limits:
            memory: "1024Mi"
            cpu: "1"
        # Set 'replica_count' below to override the default number of pods (the default is based on the 'deployment_profile_size' parameter)    
        #replica_count: 2
        memory_high_watermark: "512MB"
    # Caller_api configuration
    caller_api:
      # Set 'replica_count' below to override the default number of pods (the default is based on the 'deployment_profile_size' parameter)
      #replica_count: 2
    # HPA auto scaling configuration for caller_api.
    # These parameters will take priority over all parameters that defined under ca_configuration.global.auto_scaling section.The min_replicas and max_replicas will be used if auto_scaling.enabled is true. And the value of min_replicas will instead of replica_count.
    # The auto_scaling section should be commented out or removed if you plan to use the ca_configuration.global.auto_scaling section.
      auto_scaling:
        enabled: false
        target_cpu_utilization_percentage: 90
        min_replicas: "<Required>"  # Required if enable set to "true"
        max_replicas: "<Required>"  # Required if enable set to "true"
      resources:
        limits:
          memory: "1Gi"
          cpu: "0.6"
    # Backend configuration
    spbackend:
      # Allow to specify a specific port (nodePort) for backend.  The port number must be between 30000-32767.  A random port will be generated if blank.
      port:
      # Set 'replica_count' below to override the default number of pods (the default is based on the 'deployment_profile_size' parameter)
      #replica_count: 2
      # HPA auto scaling configuration for spbackend.
      # These parameters will take priority over all parameters that defined under ca_configuration.global.auto_scaling section. The min_replicas and max_replicas will be used if auto_scaling.enabled is true. And the value of min_replicas will instead of replica_count.
      # The auto_scaling section should be commented out or removed if you plan to use the ca_configuration.global.auto_scaling section.
      auto_scaling:
        enabled: false
        target_cpu_utilization_percentage: 90
        min_replicas: "<Required>"  # Required if enable set to "true"
        max_replicas: "<Required>"  # Required if enable set to "true"
      resources:
        limits:
          memory: "1Gi"
          cpu: "0.6"
    # Postprocessing configuration
    postprocessing:
      process_timeout: 1500
      # Set 'replica_count' below to override the default number of pods (the default is based on the 'deployment_profile_size' parameter)
      #replica_count: 2
      # HPA auto scaling configuration for postprocessing.
      # These parameters will take priority over all parameters that defined under ca_configuration.global.auto_scaling section. The min_replicas and max_replicas will be used if auto_scaling.enabled is true. And the value of min_replicas will instead of replica_count.
      # The auto_scaling section should be commented out or removed if you plan to use the ca_configuration.global.auto_scaling section.
      auto_scaling:
        enabled: false
        target_cpu_utilization_percentage: 90
        min_replicas: "<Required>"  # Required if enable set to "true"
        max_replicas: "<Required>"  # Required if enable set to "true"
      max_unavailable_count: 1
      resources:
        limits:
          memory: "800Mi"
          cpu: "0.6"
    # setup configuration
    setup:
      process_timeout: 600
      # Set 'replica_count' below to override the default number of pods (the default is based on the 'deployment_profile_size' parameter)
      #replica_count: 2
      # HPA auto scaling configuration for setup.
      # These parameters will take priority over all parameters that defined under ca_configuration.global.auto_scaling section. The min_replicas and max_replicas will be used if auto_scaling.enabled is true. And the value of min_replicas will instead of replica_count.
      # The auto_scaling section should be commented out or removed if you plan to use the ca_configuration.global.auto_scaling section.
      auto_scaling:
        enabled: false
        target_cpu_utilization_percentage: 90
        min_replicas: "<Required>"  # Required if enable set to "true"
        max_replicas: "<Required>"  # Required if enable set to "true"
      max_unavailable_count: 1
      resources:
        limits:
          memory: "1Gi"
          cpu: "0.6"
    # ocrextraction configuration
    ocrextraction:
      # When "id_card_detection.enabled" is set to true, the One Conversion Scene Text Recognition (STR) for ID cards type processing will be enabled.
      # When not set, the default is false for production and starter deployment. 
      id_card_detection:
        enabled: false
      process_timeout: 600
      # Set the replica_count below to override the default number of pods
      #replica_count: 5
      # HPA auto scaling configuration for ocrextraction.
      # These parameters will take priority over all parameters that defined under ca_configuration.global.auto_scaling section. The min_replicas and max_replicas will be used if auto_scaling.enabled is true. And the value of min_replicas will instead of replica_count.
      # The auto_scaling section should be commented out or removed if you plan to use the ca_configuration.global.auto_scaling section.
      auto_scaling:
        enabled: false
        target_cpu_utilization_percentage: 90
        min_replicas: "<Required>"  # Required if enable set to "true"
        max_replicas: "<Required>"  # Required if enable set to "true"
      max_unavailable_count: 1
      resources:
        limits:
          memory: "7Gi"
          cpu: "1"
    # classifyprocess configuration
    classifyprocess:
      process_timeout: 300
      # Set the replica_count below to override the default number of pods
      #replica_count: 2
      # HPA auto scaling configuration for classifyprocess.
      # These parameters will take priority over all parameters that defined under ca_configuration.global.auto_scaling section. The min_replicas and max_replicas will be used if auto_scaling.enabled is true. And the value of min_replicas will instead of replica_count.
      # The auto_scaling section should be commented out or removed if you plan to use the ca_configuration.global.auto_scaling section.
      auto_scaling:
        enabled: false
        target_cpu_utilization_percentage: 90
        min_replicas: "<Required>"  # Required if enable set to "true"
        max_replicas: "<Required>"  # Required if enable set to "true"
      max_unavailable_count: 1
      resources:
        limits:
          memory: "2Gi"
          cpu: "0.5"
    # processingextraction configuration
    processingextraction:
      process_timeout: 600
      # Set the replica_count below to override the default number of pods
      #replica_count: 2
      # HPA auto scaling configuration for processingextraction.
      # These parameters will take priority over all parameters that defined under ca_configuration.global.auto_scaling section. The min_replicas and max_replicas will be used if auto_scaling.enabled is true. And the value of min_replicas will instead of replica_count.
      # The auto_scaling section should be commented out or removed if you plan to use the ca_configuration.global.auto_scaling section.
      auto_scaling:
        enabled: false
        target_cpu_utilization_percentage: 90
        min_replicas: "<Required>"  # Required if enable set to "true"
        max_replicas: "<Required>"  # Required if enable set to "true"
      max_unavailable_count: 1
      resources:
        limits:
          memory: "3.5Gi"
          cpu: "1"
    # updatefiledetail configuration
    updatefiledetail:
      process_timeout: 300
      # Set the replica_count below to override the default number of pods
      #replica_count: 2
      # HPA auto scaling configuration for updatefiledetail.
      # These parameters will take priority over all parameters that defined under ca_configuration.global.auto_scaling section. The min_replicas and max_replicas will be used if auto_scaling.enabled is true. And the value of min_replicas will instead of replica_count.
      # The auto_scaling section should be commented out or removed if you plan to use the ca_configuration.global.auto_scaling section.
      auto_scaling:
        enabled: false
        target_cpu_utilization_percentage: 90
        min_replicas: "<Required>"  # Required if enable set to "true"
        max_replicas: "<Required>"  # Required if enable set to "true"
      max_unavailable_count: 1
      resources:
        limits:
          memory: "600Mi"
          cpu: "0.6"
    #Natural language extraction
    naturallanguageextractor:
      process_timeout: 300
      # Set the replica_count below to override the default number of pods
      #replica_count: 2
      # HPA auto scaling configuration for naturallanguageextractor.
      # These parameters will take priority over all parameters that defined under ca_configuration.global.auto_scaling section. The min_replicas and max_replicas will be used if auto_scaling.enabled is true. And the value of min_replicas will instead of replica_count.
      # The auto_scaling section should be commented out or removed if you plan to use the ca_configuration.global.auto_scaling section.
      auto_scaling:
        enabled: false
        target_cpu_utilization_percentage: 90
        min_replicas: "<Required>"  # Required if enable set to "true"
        max_replicas: "<Required>"  # Required if enable set to "true"
      max_unavailable_count: 1
      resources:
        limits:
          memory: "1440Mi"
          cpu: "0.5"

    # Deep Learning configuration
    deeplearning:
      process_timeout: 604800
      gpu_enabled:  # true or false.  Set it to true if you have a GPU enabled worker nodes
      nodelabel_key: # The unique node label key/value on the GPU node. For example: ibm-cloud.kubernetes.io/gpu-enabled:true.  Set this value when `gpu_enabled` is set to true.  This must be a string value
      nodelabel_value:  # The node label value on the GPU node.  For example: "true". Set this value when `gpu_enabled` is set to true. This must be a string value
      # If gpu_enabled is set to true, we expect you have at least 2 GPU to achieve HA configuration with 2 replicas.
      # Set the replica_count below to override the default number of pods
      #replica_count: 2
      # HPA auto scaling configuration for deep learning.
      # These parameters will take priority over all parameters that defined under ca_configuration.global.auto_scaling section. The min_replicas and max_replicas will be used if auto_scaling.enabled is true. And the value of min_replicas will instead of replica_count.
      # The auto_scaling section should be commented out or removed if you plan to use the ca_configuration.global.auto_scaling section.
      auto_scaling:
        enabled: false
        target_cpu_utilization_percentage: 90
        min_replicas: "<Required>"  # Required if enable set to "true"
        max_replicas: "<Required>"  # Required if enable set to "true"
      max_unavailable_count: 1
      resources:
        limits:
          memory: "10Gi"  # We recommend to increase the RAM limits if you train a large dataset.
          cpu: "2"
          gpu:  # Set this to a positive number if you have an NVIDIA GPU enabled node and when `gpu_enabled` is set to true

  ########################################################################
  ########   IBM User and Group Management Service configuration  ########
  ########################################################################
  ums_configuration:
    existing_claim_name:
    dedicated_pods: true
    service_type: Route
    routes_ingress_annotations:
    # your external UMS host name, only required if there is no sc_deployment_hostname_suffix given
    hostname:
    port: 443
    images:
      ums:
        repository: cp.icr.io/cp/cp4a/ums/ums
        tag: 21.0.3-IF007
    admin_secret_name: ibm-dba-ums-secret
    ## optional: create routes for backwards compatibility
    backwards_compatibility_routes:
    ## optional for secure communication with UMS
    external_tls_secret_name:
    ## optional for secure communication with UMS
    external_tls_ca_secret_name:
    ## optional for secure communication with UMS
    external_tls_teams_secret_name:
    ## optional for secure communication with UMS
    external_tls_scim_secret_name:
    ## optional for secure communication with UMS
    external_tls_sso_secret_name:

    use_custom_jdbc_drivers: false
    use_custom_binaries: false
    custom_secret_name:

    oauth:
      ## optional: full DN of an LDAP group that is authorized to manage OIDC clients, in addition to primary admin from admin secret
      client_manager_group:
      ## optional: full DN of an LDAP group that is authorized to manage app_tokens, in addition to primary admin from admin secret
      token_manager_group:
      ## optional: lifetime of OAuth access_tokens. default is 7200s
      access_token_lifetime:
      ## optional: lifetime of app-tokens. default is 366d
      app_token_lifetime:
      ## optional: lifetime of app-passwords. default is 366d
      app_password_lifetime:
      ## optional: maximum number of app-tokens or app-passwords per client. default is 100
      app_token_or_password_limit:
      ## optional: encoding / encryption when storing client secrets in OAuth database. Default is xor for compatibility. Recommended value is PBKDF2WithHmacSHA512
      client_secret_encoding:

    # TODO - adapt log parameters when Volume is used
    logs:
      console_format: json
      console_log_level: INFO
      console_source: message,trace,accessLog,ffdc,audit
      trace_format: ENHANCED


    #### If dedicated_pods is set to false, the UMS capabilities sso, scim and teamserver
    #### run in the same pods and share this configuration
    replica_count: 2
    resources:
      limits:
        cpu: 500m
        memory: 512Mi
      requests:
        cpu: 200m
        memory: 256Mi
    autoscaling:
      enabled: true
      min_replicas: 2
      max_replicas: 5
      target_average_utilization: 98
    custom_xml:
      logs:
        traceSpecification: "*=info"

    #### If dedicated_pods is set to true, the UMS capabilities sso, scim and teamserver
    #### run in dedicated pods and are configured separately

    # Configuration for sso pods
    sso:
      ## optional: full DN of an LDAP group that is authorized to manage OIDC clients, in addition to primary admin from admin secret
      client_manager_group:
      ## optional: full DN of an LDAP group that is authorized to manage app_tokens, in addition to primary admin from admin secret
      token_manager_group:
      ## optional: lifetime of OAuth access_tokens. default is 7200s
      access_token_lifetime:
      ## optional: lifetime of app-tokens. default is 366d
      app_token_lifetime:
      ## optional: lifetime of app-passwords. default is 366d
      app_password_lifetime:
      ## optional: maximimum number of app-tokens or app-passwords per client. default is 100
      app_token_or_password_limit:
      ## optional: encoding / encryption when sotring client secrets in OAuth database. Default is xor for compatibility. Recommended value is PBKDF2WithHmacSHA512
      client_secret_encoding:
      replica_count: 2
      resources:
        limits:
          cpu: 500m
          memory: 512Mi
        requests:
          cpu: 200m
          memory: 256Mi
      autoscaling:
        enabled: true
        minReplicas: 2
        maxReplicas: 5
        targetAverageUtilization: 98
      custom_xml:
      logs:
        traceSpecification: "*=info"

    # configuration for scim pods
    scim:
      replica_count: 2
      resources:
        limits:
          cpu: 500m
          memory: 512Mi
        requests:
          cpu: 200m
          memory: 256Mi
      autoscaling:
        enabled: true
        minReplicas: 2
        maxReplicas: 5
        targetAverageUtilization: 98
      custom_xml:
      logs:
        traceSpecification: "*=info"

    # configuration for teamserver pods
    teamserver:
      replica_count: 2
      resources:
        limits:
          cpu: 500m
          memory: 512Mi
        requests:
          cpu: 200m
          memory: 256Mi
      autoscaling:
        enabled: true
        minReplicas: 2
        maxReplicas: 5
        targetAverageUtilization: 98
      custom_xml:
      logs:
        traceSpecification: "*=info"
      ## Specify an LDAP Admin group (e.g., admingroup: "cn=ADPEnvironmentOwners,dc=example,dc=org" where
      ## the ADPEnvironmentOwners group will to be the default UMS teamserver administrators as required for
      ## Automation Document Processing (ADP) capability)
      admingroup: "<Required>"
      # optional, default false: enable debug output for Teamserver-to-BTS migration
      migration_debug: false
      # optional, default false: drop tables in BTS database before Teamserver-to-BTS migration
      migration_droptables: false
      # optional, default false: execute Teamserver-to-BTS migration regardless of Teamserver uninstall
      migration_test: false

  ########################################################################
  ######## IBM FileNet Content Manager Initialization configuration ######
  ########################################################################
  ## NOTE: Automation Document Processing (ADP) capability is depended on CPE component (part of FNCM)
  ## The deployment of FNCM will be initialized with the default values assigned to the parameters below.
  ## The initialization process includes the creation of the P8 domain, the creation of the directory services,
  ## the assignments of users/groups to the P8 domain and object store(s), the creation of the object store(s),
  ## the creation/addition of add-ons for each object store, the enablement of workflow for each object store, the
  ## creation of Content Search Services servers, index areas, and the enabling of Content-based Retrieval (CBR) for each object store.
  ## In addition, the creation of Navigator desktop will also occur.
  ## If any of the values below does not fit your infrastructure, then change the value to correpond to your configuration
  ## (e.g., "CEAdmin" is the default user for ic_ldap_admin_user_name parameter and if you do not have "CEAdmin" user in your directory
  ## server and have a different user, then replace "CEAdmin" with your own user).  Otherwise, the rest of the values should remain as default.
  initialize_configuration:
    ic_domain_creation:
      domain_name: "P8DOMAIN"
      encryption_key: "128"
    ic_ldap_creation:
      ic_ldap_admin_user_name:
      - "<Required>" # user name for P8 domain admin, for example, "CEAdmin".  This parameter accepts a list of values.
      ic_ldap_admins_groups_name:
      - "<Required>" # Specify an LDAP Admin group (CE Environment Owners) as domain admin (required for "document_processing" capability)
      ic_ldap_name: "ldap_name"
    ic_obj_store_creation:
      object_stores:
      - oc_cpe_obj_store_display_name: "DEVOS1" # "<Required>"
        oc_cpe_obj_store_symb_name: "DEVOS1" # "<Required>"
        oc_cpe_obj_store_conn:
          name: "objectstore1_connection"
          site_name: "InitialSite"
          dc_os_datasource_name: "DEVOS1DS"
          dc_os_xa_datasource_name: "DEVOS1DSXA"
        oc_cpe_obj_store_admin_user_groups:
        - "<Required>" # Specify an LDAP Admin group (CE Environment Owners) as domain admin (required for "document_processing" capability)
        # Array of users
        oc_cpe_obj_store_basic_user_groups:
        oc_cpe_obj_store_addons: true
        oc_cpe_obj_store_addons_list:
        # "5.2.1 Base Application Extensions"
        - "{CE460ADD-0000-0000-0000-000000000004}"
        # "5.2.1 Base Content Engine Extensions"
        - "{CE460ADD-0000-0000-0000-000000000001}"
        # "5.2.1 Process Engine Extensions"
        - "{CE460ADD-0000-0000-0000-000000000003}"
        # "5.2.1 Publishing Extensions"
        - "{CE460ADD-0000-0000-0000-000000000005}"
        # "5.2.1 Stored Search Extensions"
        - "{CE511ADD-0000-0000-0000-000000000006}"
        # "5.2.1 Workplace Access Roles Extensions"
        - "{CE460ADD-0000-0000-0000-000000000008}"
        # "5.2.1 Workplace Base Extensions"
        - "{CE460ADD-0000-0000-0000-000000000007}"
        # "5.2.1 Workplace E-mail Extensions"
        - "{CE460ADD-0000-0000-0000-000000000009}"
        # "5.2.1 Workplace Forms Extensions"
        - "{CE460ADD-0000-0000-0000-00000000000A}"
        #  "5.2.1 Workplace Templates Extensions"
        - "{CE460ADD-0000-0000-0000-00000000000B}"
        # "5.2.1 Workplace XT Extensions"
        - "{CE460ADD-0000-0000-0000-00000000000D}"
        # "5.2.1 Thumbnail Extensions"
        - "{CE511ADD-0000-0000-0000-00000000000F}"
        # "5.2.1 Teamspace Extensions"
        - "{CE511ADD-0000-0000-0000-000000000010}"
        # "5.2.1 Custom Role Extensions
        - "{CE511ADD-0000-0000-0000-000000000015}"
        # "5.5.2 Core Collaboration Extensions"
        - "{CE552ADD-0000-0000-0000-00000000001C}"
        # "5.2.1 Social Collaboration Role Extensions"
        - "{CE521ADD-0000-0000-0000-000000000016}"
        # "5.5.1 Social Collaboration Base Extensions"
        - "{CE551ADD-0000-0000-0000-000000000011}"
        oc_cpe_obj_store_asa_name: "demo_storage"
        oc_cpe_obj_store_asa_file_systems_storage_device_name: "devos1_file_system_storage"
        oc_cpe_obj_store_asa_root_dir_path: "/opt/ibm/asa/devos1_storagearea1"
        oc_cpe_obj_store_enable_workflow: true
        oc_cpe_obj_store_workflow_region_name: "design_region_name"
        oc_cpe_obj_store_workflow_region_number: 1
        oc_cpe_obj_store_workflow_data_tbl_space: "VWDATA_TS"
        oc_cpe_obj_store_workflow_index_tbl_space: ""
        oc_cpe_obj_store_workflow_blob_tbl_space: ""
        oc_cpe_obj_store_workflow_admin_group: "P8Administrators"
        oc_cpe_obj_store_workflow_config_group: "P8Administrators"
        oc_cpe_obj_store_workflow_date_time_mask: "mm/dd/yy hh:tt am"
        oc_cpe_obj_store_workflow_locale: "en"
        oc_cpe_obj_store_workflow_pe_conn_point_name: "pe_conn_devos1"
        # Enable the content event emitter only when deploying BAI.
        # Default value is false if not specified in the CR.
        oc_cpe_obj_store_enable_content_event_emitter: false
        # Enable/disable object store database compression.  Default is false.
        oc_cpe_obj_store_enable_compression: false
        # Enable object store for publishing of document processing application.
        # For Evaluation (Starter) deployment, the default object store is "DEVOS1"
        # By default, the object named "DEVOS1" will be enabled.  If you have defined
        # any other object stores (e.g., OS1, etc) and wish to enable for publishing of
        # document processing application, then set oc_cpe_obj_store_enable_document_processing to "true"
        oc_cpe_obj_store_enable_document_processing: true

      ## Configuration for the application engine object store
      ## Display name for the application engine object store to create
      - oc_cpe_obj_store_display_name: "AEOS" # "<Required>"
        ## Symbolic name for the application engine object store to create
        oc_cpe_obj_store_symb_name: "AEOS" # "<Required>"
        oc_cpe_obj_store_conn:
          ## Object store connection name
          name: "AEOS_connection" #database connection name
          ## The name of the site
          site_name: "InitialSite"
          ## Add the name of the object store database
          dc_os_datasource_name: "AEOS"
          ## The XA datasource
          dc_os_xa_datasource_name: "AEOSXA"
        ## Admin user group
        oc_cpe_obj_store_admin_user_groups:
        - "<Required>" # user name and group name for object store admin, for example, "CEAdmin" or "P8Administrators".  This parameter accepts a list of values.
        ## An array of users with access to the object store
        oc_cpe_obj_store_basic_user_groups:
        ## Specify whether to enable add-ons
        oc_cpe_obj_store_addons: true
        ## Add-ons to enable for Content Platform Engine
        oc_cpe_obj_store_addons_list:
        # "5.2.1 Base Application Extensions"
        - "{CE460ADD-0000-0000-0000-000000000004}"
        # "5.2.1 Base Content Engine Extensions"
        - "{CE460ADD-0000-0000-0000-000000000001}"
        # "5.2.1 Process Engine Extensions"
        - "{CE460ADD-0000-0000-0000-000000000003}"
        # "5.2.1 Publishing Extensions"
        - "{CE460ADD-0000-0000-0000-000000000005}"
        # "5.2.1 Stored Search Extensions"
        - "{CE511ADD-0000-0000-0000-000000000006}"
        # "5.2.1 Workplace Access Roles Extensions"
        - "{CE460ADD-0000-0000-0000-000000000008}"
        # "5.2.1 Workplace Base Extensions"
        - "{CE460ADD-0000-0000-0000-000000000007}"
        # "5.2.1 Workplace E-mail Extensions"
        - "{CE460ADD-0000-0000-0000-000000000009}"
        # "5.2.1 Workplace Forms Extensions"
        - "{CE460ADD-0000-0000-0000-00000000000A}"
        #  "5.2.1 Workplace Templates Extensions"
        - "{CE460ADD-0000-0000-0000-00000000000B}"
        # "5.2.1 Workplace XT Extensions"
        - "{CE460ADD-0000-0000-0000-00000000000D}"
        # "5.2.1 Thumbnail Extensions"
        - "{CE511ADD-0000-0000-0000-00000000000F}"
        # "5.2.1 Teamspace Extensions"
        - "{CE511ADD-0000-0000-0000-000000000010}"
        # "5.2.1 Custom Role Extensions
        - "{CE511ADD-0000-0000-0000-000000000015}"
        # "5.5.2 Core Collaboration Extensions"
        - "{CE552ADD-0000-0000-0000-00000000001C}"
        # "5.2.1 Social Collaboration Role Extensions"
        - "{CE521ADD-0000-0000-0000-000000000016}"
        # "5.5.1 Social Collaboration Base Extensions"
        - "{CE551ADD-0000-0000-0000-000000000011}"
        oc_cpe_obj_store_enable_compression: false
        ## Provide a name for the Advance Storage Area
        oc_cpe_obj_store_asa_name: "demo_storage"
        ## Provide a name for the file system storage device
        oc_cpe_obj_store_asa_file_systems_storage_device_name: "demo_file_system_storage"
        ## The root directory path for the object store storage area
        oc_cpe_obj_store_asa_root_dir_path: "/opt/ibm/asa/osae_storagearea"
        ## Specify whether to enable workflow for the object store
        oc_cpe_obj_store_enable_workflow: false
        ## Specify a name for the workflow region
        oc_cpe_obj_store_workflow_region_name: "<Required>"
        ## Specify the number of the workflow region
        oc_cpe_obj_store_workflow_region_number: 1
        ## Specify a table space for the workflow data
        oc_cpe_obj_store_workflow_data_tbl_space: "VWDATA_TS"
        ## Optionally specify a table space for the workflow index
        oc_cpe_obj_store_workflow_index_tbl_space: "VWINDEX_TS"
        ## Optionally specify a table space for the workflow blob.
        oc_cpe_obj_store_workflow_blob_tbl_space: "VWBLOB_TS"
        ## Designate an LDAP group for the workflow admin group.
        oc_cpe_obj_store_workflow_admin_group: "<Required>"
        ## Designate an LDAP group for the workflow config group
        oc_cpe_obj_store_workflow_config_group: "<Required>"
        ## Default format for date and time
        oc_cpe_obj_store_workflow_date_time_mask: "mm/dd/yy hh:tt am"
        ## Locale for the workflow
        oc_cpe_obj_store_workflow_locale: "en"
        ## Provide a name for the connection point
        oc_cpe_obj_store_workflow_pe_conn_point_name: ""
    ic_css_creation:
      - css_site_name: "Initial Site"
        css_text_search_server_name: "{{ meta.name }}-css-1"
        affinity_group_name: "aff_group"
        css_text_search_server_status: 0
        css_text_search_server_mode: 0
        css_text_search_server_ssl_enable: "true"
        css_text_search_server_credential: "RNUNEWc="
        css_text_search_server_host: "{{ meta.name }}-css-svc-1"
        css_text_search_server_port: 8199
    ic_css_index_area:
      - object_store_name: "DEVOS1"
        index_area_name: "devos1_index_area"
        affinity_group_name: "aff_group"
        root_dir: "/opt/ibm/indexareas"
        max_indexes: 20
        max_objects_per_index: 10000
    ic_enable_cbr:
      - object_store_name: "DEVOS1"
        class_name: "Document"
        indexing_languages: "en"
    ic_icn_init_info:
      icn_repos:
      - add_repo_id: "devos1_repo1"
        add_repo_ce_wsi_url: "http://{{ meta.name }}-cpe-stateless-svc:9080/wsi/FNCEWS40MTOM/"
        add_repo_os_sym_name: "DEVOS1"
        add_repo_os_dis_name: "DEVOS1"
        add_repo_workflow_enable: false
        add_repo_work_conn_pnt: "pe_conn_devos1:1"
        add_repo_protocol: "FileNetP8WSI"
      ## If you have more than 1 object store, uncomment this section for initialization of the object store.
      # - add_repo_id: "test_repo2"
      #   add_repo_ce_wsi_url: "http://{{ meta.name }}-cpe-stateless-svc:9080/wsi/FNCEWS40MTOM/"
      #   add_repo_os_sym_name: "OS02"
      #   add_repo_os_dis_name: "OS02"
      #   add_repo_workflow_enable: true
      #   add_repo_work_conn_pnt: "pe_conn_os02:1"
      #   add_repo_protocol: "FileNetP8WSI"
      icn_desktop:
      - add_desktop_id: "demo"
        add_desktop_name: "icn_desktop"
        add_desktop_description: "This is ICN desktop"
        add_desktop_is_default: false
        add_desktop_repo_id: "devos1_repo1"
        add_desktop_repo_workflow_enable: false

  ########################################################################
  ######## IBM FileNet Content Manager Verification configuration ######
  ########################################################################
  ## After the initialization process (see section above), the verification process will take place.
  ## The verification process ensures that the FNCM and BAN components are functioning correctly.  The verification
  ## process includes creation of a CPE folder, a CPE document, a CBR search, verifying the workflow configuration,
  ## and validation of the ICN desktop.
  verify_configuration:
    vc_cpe_verification:
      vc_cpe_folder:
      - folder_cpe_obj_store_name: "DEVOS1"
        folder_cpe_folder_path: "/TESTFOLDER"
      vc_cpe_document:
      - doc_cpe_obj_store_name: "DEVOS1"
        doc_cpe_folder_name: "/TESTFOLDER"
        doc_cpe_doc_title: "test_title"
        DOC_CPE_class_name: "Document"
        doc_cpe_doc_content: "This is a simple document test"
        doc_cpe_doc_content_name: "doc_content_name"
      vc_cpe_cbr:
      - cbr_cpe_obj_store_name: "DEVOS1"
        cbr_cpe_class_name: "Document"
        cbr_cpe_search_string: "is a simple"
      vc_cpe_workflow:
      - workflow_cpe_enabled: false
        workflow_cpe_connection_point: "pe_conn_devos1"
    vc_icn_verification:
      - vc_icn_repository: "devos1_repo1"
        vc_icn_desktop_id: "demo"
